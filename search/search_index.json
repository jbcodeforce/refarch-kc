{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Container Shipment EDA reference implementation The IBM Event Driven architecture reference implementation illustrates the deployment of real time analytics on event streams in the context of container shipment in an event driven architecture with event backbone, functions as service and microservices, and aims to illustrate the different event driven patterns like event sourcing, CQRS and Saga. What you will learn How to apply the event storming methodology and workshop to analyze the business process for fresh good shipment over sees. How to transform Domain Driven Design aggregates to microservices How to implement the different microservices using the event-driven pattern like CQRS pattern with event sourcing done in Apache Kafka or IBM Events Streams How to implement a Test Driven Development for the Order microservice uisng mockito to avoid Kafka dependency Target Audiences You will be greatly interested by the subjects addressed in this solution if you are... An architect, you will get a deeper understanding on how all the components work together, and how to address resiliency, high availability. A developer, you will get a broader view of the solution end to end and get existing starting code, and practices you may want to reuse during your future implementation. We focus on event driven solution in hybrid cloud addressing patterns and non-functional requirements as CI/CD, Test Driven Development, ... A project manager, you may understand all the artifacts to develop in an EDA solution, and we may help in the future to do project estimation.","title":"Home"},{"location":"#container-shipment-eda-reference-implementation","text":"The IBM Event Driven architecture reference implementation illustrates the deployment of real time analytics on event streams in the context of container shipment in an event driven architecture with event backbone, functions as service and microservices, and aims to illustrate the different event driven patterns like event sourcing, CQRS and Saga.","title":"Container Shipment EDA reference implementation"},{"location":"#what-you-will-learn","text":"How to apply the event storming methodology and workshop to analyze the business process for fresh good shipment over sees. How to transform Domain Driven Design aggregates to microservices How to implement the different microservices using the event-driven pattern like CQRS pattern with event sourcing done in Apache Kafka or IBM Events Streams How to implement a Test Driven Development for the Order microservice uisng mockito to avoid Kafka dependency","title":"What you will learn"},{"location":"#target-audiences","text":"You will be greatly interested by the subjects addressed in this solution if you are... An architect, you will get a deeper understanding on how all the components work together, and how to address resiliency, high availability. A developer, you will get a broader view of the solution end to end and get existing starting code, and practices you may want to reuse during your future implementation. We focus on event driven solution in hybrid cloud addressing patterns and non-functional requirements as CI/CD, Test Driven Development, ... A project manager, you may understand all the artifacts to develop in an EDA solution, and we may help in the future to do project estimation.","title":"Target Audiences"},{"location":"analysis2microsvcs/","text":"From Analysis to Microservice Specifications Goals and outline of section This section describes the design step which uses output from the event storming session and subsequent analysis and derives a set of micro services design specification. The goals for ts design step and the resulting specifications are: Highly modular cloud native microservices Event coupled microservices - facilitating independent modification and evolution of each microservice separatelys Allow for event sourcing \u2013 eventual correctness and recovery using event base) Illustrate CQRS and its scaling advantages Since we are delivering a demonstration application there will be some simulator / scaffolding / testing services mixed in with the required business processing. This is a common occurrence in agile development and it may be helpful to show how decision to scope and simplify a particular build and test step interact with decisions relating strictly to microservices design. Requirements for scalability, coupling of microservices only through the event back bone and eventual correctness differentiate this step from previous Event Storming and Domain Driven Design activities which were 100% business requirement driven. Starting materials generated during Event Storming and Analysis In this microservices specification step we make use of the following materials generated during Event Storming and analysis of the Container Shipment example problem: Event Sequence flow Events \u2013 business description Critical events Aggregates and services * Users \u2013 roles user stories * Commands * Event linkages * Policies * Event prediction and probability flows * Data ( Conceptual ) The derivation of these material was described in: Analysis . Event linked microservices design - structure A complete microservices specification ( the target of this design step ) will include specifications of the following: Event Topics * Used to configure the Kafka Event Backbone Event types within each event topic Microservices: * These are finer grained than aggregates * May separate query and command; possibly multiple queries * May Separate whether simulation or business processing component * Demonstration Control \u2013main UI * Scaffolding and testing services - whether local and cloud versions Microservice specification ( for each identified * Data within Each microservice * APIs ( Synchronous ) * Topics and events Subscribed to * Events published / emitted List of end to end interactions * List of logic segments per microservice Recovery processing, scaling * We expect this to be highly patterned and template driven not requiring example-specific design With the above information coding of each microservice and other components of the sprint should be straightforward. Steps in the design process Here we describe in generic terms, each step in the process of deriving event-linked microservice specification. In following section we will describe in more detail how each of these steps plays out in the specific context of the the container shippment example. List of generic steps: Step 1 - limit the context and scope for this particular build / sprint we assume that we are developing a particular build for a sprint within some agile development ; additional functions and complexity may be added in later sprints working from the initial list of aggregates, select which aggregates will be included in this build for each aggregate possible choices are: (1) to completely skip and workaround the aggregate in this build (2) to include a full lifecycle implementation of the aggregate (3) to provide a simplified lifecycle implementation - typicall a table of entities is initialized at s. tart up, and state changes to existing entities are tracked determine whether there are simulation services or predictive analytics service to be included in the build identify the external query apis and command apis which this build will support create entity lifecycle diagrams for entites having a full lifecycle implementation in this build / sprint . Step 2 - identify specific microservices in each aggregate each aggregate will be implemented as some composition of (1) a command microservice managing state chsnges to the entities in this aggregate (2) possibly one or more separate ( CQRS) query services providing internal or external API query capabilities (3) additional simulation, predictive analytics or User Interface microservices The command microservice will be built around and manage a collection of active entites for the aggregate, keyed by some primary key The separation of each aggregate into specific component microservices as outlined above, will be a complete list of microservices for the build / sprint. Identify the data collections, and collection organization (keying structure) in each command and query microservice for this build. Step 3 - generate microservice interaction diagrams for the build The diagram will show API calls initiating state change It shows for each interaction whether this is a synchronous API calls or an asynchronous event interaction via the event backbone The diagram labels each specific event interaction between microservices trigerring a state change ( Typically queries are synchronous API calls since the caller cannot usefully proceeed until a result is returned ) From this we can extract: (1) a complete list of event types on each topic, with information passed on each event type (2) the complete list of \u201clogic segments\u201d for each microservice processing action in response to an API call or initiating event When, at the next level of detail, the individual fields in each event are specified and typed, the CloudEvents standard in https://github.com/cloudevents/spec should be assumed as a start point Step 4 - specify recovery approach in case a microservice fails If a microservice fails it will need to recover its internal state date by resubscribing to one or more topics on the event bus In general, commamd and query microservices will have a standard pattern for doing this Any custom event filtering and service specific logic should be specified Concepts and rationale underlying this design approach What is the difference between event information stored in the event backbone and state data stored in the microservices ? the event information stored persistently in the event backbone is organized by topic and, within each topic, entirely by event time-of-occurrence. the state information in a command microservice is a list (collection) of all currently active entities of the owning aggregate ( e.g. all orders, all voyages etc ) and the current state of each such entity each command microservice will consist of a collection of entity records keyed by primary key this is complementary to the historically organized information in the event backbone. When is it OK to be using synchronous interactions between services instead of asyncrhonous event interacts through the event backbone? For non-state-changing queries, for which the response is always instantaneously available a synchronous query callmy be Ok and will provide a simpler more understandable interface. Any processing which can be though of as being triggered by some state change in anothe aggregate should be modelled with an asynchronous, because as the solution eveolves other new microservices may also need to be aware of this event. We do not want to have to go back and change logic n the service where this event originated to have that microservice actively report the event to all potential consumers. How do we save microservices from having to maintain data collections with complex secondary indexing for which eventual consistency will be hard to implement? Each command microservice should do all its state changing updates using the primary key lookup only for its entities. Each asynchronous event interaction between microservices should carry primary entityIds ( orderID, VoyageID, shipID) for any entities associated with the interaction. Each query which might require speciaoized secondary indexing to respond to queries can be implemented in a separate CQRS query service which subscribes to events to do all internal updating and receives events from the event backbone in a ( Consistent) eventually correct order. This allows for recovery of any failed service by rebuilding it in \"eventually correct\" order. Specific application to Container Shipment example In this section we discuss how the generic steps introduced above can be applied for the Container shipping example Step1 - context and scope for demonstration build An initial scoping decision is that the demonstration will address shipment orders and shipment progress initiated by the \"manufacturer\" of the goods with the shipment company. In the context of the example there is also discussion of manufacturer and retailer reaching some agreement on the goods to be delivered but this is not part of the demonstrated capabilities. The Event Storming analysis of the shipment problem was end-to-end and involved many aggregates including: Orders, Voyages, Trucking operations both at the source (maufacturer pickup ) and destination (retailer delivery), Customs and export interactions, Container loading into ship at source port and unloading from ship at destination port, containers and fleet of ships. To have a simple initial demonstration build showing the role of EDA architecture and event coupled microservices, as an initial step towards development of a more complete system using agile incremental development and deployment, the initial demonstration build makes the following simplifications and scoping decisions: This build will have no implementation of: Trucking operations, Customs and export, or Dockside Handling aggregates It will show a full lifecyle for a manufacturer user to place an order for shipment, seeing a filled container placed on board ship transported to the destination port and delivered. It will include a simulation Service for ship movements - tracking the movement of ships carrying containers It will include simulation and analytics for Container temperatures in while onboard ship * It will provide a query for a user to track an order and the current location and state of the associated shipment Based on the scope selection above, active aggregates in the build will be: Orders - with support for a complete order lifecycle Voyages - list of planned port to port passges with dates and manifests for each sip Containers - with allocation of a container to each order and temperature tracking of refrigerated containers Ships - with tracking of current voyage and current geographical position of each container ship The event backbone will be configured with a topic for each of the above aggregated. We expect to see multiple event typs on each topic, but subscriptions and sequencing of events will be within these high level topics. Command API.s will be provided to: place a new shipment order track an existing order, eith to confirmits booking state or to resolve the actual location and status of the container in transit * modify an order request which could not be booked within the requested time window A more complete and complex build could include an api for a shipping company person to optimally and manually assign orders to voyages, but for this initial demonstration we will automate this process and assign orders automatilly to the first voyage found meeting the requested requirements. Specifically, each order is assigned to the first located voyage: going from the port nearest to pickup location to the port nearest the delivery location, within the requested time window for pickup and delivery with available capacity for an additional container on that voyage. Additional APIwill be need: to initiate the overall demonstration to manage and view specific simulation component - container simulation and analytics abd ship simulation and analytics. Shipment order lifecycle and state change events The scoping decisions for the demonstration build listed above are reflected in a shipment order life cycle diagram shown below. A shipment order is initially created with an API call made by a manufacturer. The order request specifies: the pickup location where emptry container will be loaded the delivery location where the container is to be delivered to (we expect this to be in a remote country requiring a sea voyage ) * the shipment time window i.e. * earliest date at which goods are available at pickup location for loading into the container * date by which delivery to the destination address is required Since our initial demonstration build expects to show refrigeration behavior snd track preservation of a cold chain, we asume that orders are for some commodity which requires refrigeration during its shipment. A graphical view of this API with some additional field specification is provided in Create order Request . When a new shipment order is placed, the shipping company must determine whether there is available capacity in some planned ship voyage which meets all the requirements specified by the manufacturer / customer. If there is a planned voyage with available cpacity for ne additional container going from the source port nearest the pickup location to the destination port nearest to the delivery location then the order can transition to state=BOOKED and positive confirmation of the order returned to the requester. If no such voyage is available then the shipment order transitions to state=REJECTED(No Availability) and this is reported back to the requester. Once an order is BOOKED, then the expected dates and locations where for which a container will be needed are known. A request can be issued to book a specific (refrigerated) container for use with this shipment. We assume that the shipping company always has enough container available to meet expected shipment demand, hence the shipment order will transition to state=CONTAINER_ALLOCATED when this container booking is received. Since the scope for this demonstration build excliuded the simulation of trucking operations to get the goods from the manufacturer's pickup location, export clearance and actual dockside loading operations, once an order has a container allocated it is \" ready to go\" and transitions to state=FULL_CONTAINER_VOYAGE_READY. The actual event of recording the container as being on board ship and at sea will not happen until simulated time in the demonstration reaches the scheduled start of the voyage on which that container is booked and the container ship assigned to that voyage is in the source port and also ready to go. At that point in simulated time, the state of the shipment order changes from state = FULL_CONTAINER_VOYAGE_READY to state = CONTAINER_ON_SHIP. While the order has state = CONTAINER_ON_SHIP, then we will be receiving temperature information from the COntainer simulation and analytics and Ship position information from the ship simulation service. Both provide a continuous streaming souces of information which should be considered part of the extended shipment state. After some period of simulated time, the ship will reach the destination port of the voyage. at this time the Oder transitions to state = CONTAINER_OFF_SHIP since our scope excluded simulation of actual dockside unloading information. Since we are not modelling customs clearance or trucking operations, there are no further events to be modelled until the order state = CONTAINER_DELIVERED. Since we are not modelling invoicing and billing operations the Container can be deallocated from this order and retruned to some pool of free containers. When that has occurred the oder state can be considered state = ORDER_COMPLETED. We have described the the mornal, exception-free path first. There are two exception cases modelled. At the time a new shipment order is requested, there may be no voyage with available capacity meeting the location and time requirements of the request. When this occurs, the manufacturer/user is informed and the order state becomes state= REJECTED (No Availability). At this point the user can modify the order with a second API requests changing dates or possibly locations. This retry request could still fail returning the order back to state = REJECTED ( No availability). Alternatively the changes in dates and location could be anough for an available voyage to be found. When this occurs the order will transition to state = BOOKED modified. * If an API call to modify an order is made and the order is in some state different from state=REJECTED(No availability), we reject the API request. There could be race conditions, the order is in the process of being assigned to a voyage, or complex recovery issues, - what if the order is already in a container and at sea when a modify order is received ? Full treatment of these complex business specific issues is out of scope and avoided by the state check in the modify order call API call We also model the exception condition when the refrigeration unit in a container fails or is misset or over loaded. If the temperature in the container goes outside the service level rance for that shipment the goods must be considered spoiled. The oreder will transition from state = CONTAINER_ON_SHIP to state = ORDER_SPOILED(Temperature out of Range). Some complex business recovery such as compensating the customer and possibly scheduling a replcement shipment may be required. The details will be contract specific and outside the scope , but we do include the use of Streaming event container analytics to detect the spoilage and use rule based real-time /edge adjustments of the refrigeration gear to avoid spoilage in the demonstration simulation. Step 2 - microservices and microservice owned data for demonstration build In this step we fix the specific microservices for each aggregate and te data organization for each microservice. Orders Aggregate For Orders we will need an orders-command-ms which will maintain a list of all current active orders and the current state of each order. The order state will as described above. The collection of active orders will be keyed by orderID. The orders-command-ms will offer APIs for create order and modify order since these are external interactions. It makes sense to use CQRS and separate out order tracking into a separate oders-query-ms since: The demand for order tracking might have significantly more intense scalability needs than order commands * orders are typically created once and changes state a handful of times; there could be many different users querying status of a particular orders independently and each requesting tracking multiple time for each order to determine if there is some delay expected Order state tracking information should probably be organized by requesting customer NOT bu order ID * since customers should be ollowed to see status on their own orders but not on other customer's orders * when the shipping company is tracking an order it is most frequently doing so on behalf of a specific customer With this approach orders-query-ms becomes a CQRS query service with internal state updated from the event backbone, and an order tracking API Voyages Aggregate For Voyages we will need a voyages-command-ms which will maintain a list of all voyages and their current state. In any given run of the demonstration we will work with a fixed set of voyages - effectively the schedule for the container fleet - so there is no need for an API t create additional voyages. The voyage definition will be read from file when the build is initializing. We expect this voyage data to be well formed: each voyage has a container ship in the fleet allocated to make the voyage the voyages assigned to any one ship are properly \"chained\". For the sequence of voyages assigned to any one container ship, the destination port of the nth voyage is always the start port of the (n+1)th voyage The states of a yoyage are: SCHEDULED - in this state it can accept order bookings, knows how much free space is available for additional bookings, and knows the orderIDs of each shipment already booked on the voyage IN_PROGRESS - in this state it includes a manifest a list of the orderIDs and containerIDs on board the ship * COMPLETED - a voyage in the completed state supports tracing continers, may know which containers in the voyage were spoiled etc It will be helpful for the voyage-command-ms to include a query service to lookup voyages with a particular source port and destination port in a particular time windaw. This will help process booking request event but does not need to be an external API hence there is no strong argument for realizing this as a separate CQRS query service. Containers Aggregate For Containers we will need we will use a containers-command-ms to maintain a list of defined containerIDs and track the state of each container. A fixed set of valid container IDs will be initialized at demonstration start time. As noted previously we will assume this to be enough for all requested orders to be assigned a container without availability issues. Since the collection of containers is fixed the component will not need a cmmand API The container current state maintained in container-command-ms is: state = FREE - this container is not in use and is available to be assigned to a new shipment order state = ALLOCATED - thei container is allocated ot order orderID and potentially in use for that shipment We will be modelling and performing streaming analytics on temperature inside a (refrigerated) container. Hence there will be a separate services performing this streaming analytics and simulation: container-streaming-svc. Conceptually, while a container is ALLOCATED to a shipment order with state = CONTAINER_ON_SHIP, its internal temperature and power usage will be maintained as streaming state by the container-streaming-svc. Fleet/Ships Aggregate For Ships we wil have a monolithic fleet simulation service providing continuous simulation of ship position for each ship and modelling of ship events. This service will include a UI to enable viewing the positions and states of the ships. It may have a separate UI to control the overall demonstration. There is no requirement for any separate microservice maintining additional information on ship state. Step3 - specifing all interactions in a logic flow for the demonstration build Using the understanding of the event flow from the Event Storming session, the scoping of this build, the list of microservices and data within each microservices developed in the steps above, we can write out in a complete interrraction flow. This flow illustrates how the microservices are linked together via the Event backbone using event interractions for all non API interractions between distinct microservices. Command microservice interactions - order create through voyage start with container on board The diagram below shows all command interactions from initial order creation through voyage start. The grey(shaded) columns of processing blocks are organized to show processing by the different command microservices. Column 1 shows processby the orders-command-ms Column 2 shows processing by the voyages-command-ms Column 3 shows processing by the containers-command-ms and in a later figure by containers-streaming-ms Column 4 shows processing by the fleet/ships-simulator-ms Comments on steps in the command flow: A new shipment order request is initiated with the syncronous createOrder API at top left * the orders-command-ms will create a new order record in its tale of active orders and populate it with order details * a NewOrder event is emitted on the Orders Topic * the generated orderID or the new shipment order is returned to the requester in the createOrder response. This enables the requester to query the status of an order and possibly modify the parameters of an unbooked order. * the voyages-command-ms subscibes to all newOrder events on the Orders topic and tries to assign each new order to an available voyage * this operation is simplified by internally maintainin some list of vayages organized by port pait ( Starting port - ending port combination) and by time within port pair. * using such a list each voyage matching the port pair requirement of the new order can be checked or available capacity * if a voyage meeting all requirements for the new order is found, a booking event is emitted; if not, a rejected(No availability) event is emitted * a booked event causes state change in both the voyage - available capacity reduced, new order added to bookings - and to the order. We choose to make both booking and rejected (no Availabiity) events on the Orders topic rather than the Voyages topic the orders-command-ms subscribes to Orders: booking and to Orders: Rejected(no availability) events and updates the current state of the affected order with the received information. * for bookings, the current state of order is updated with the booking informationg including VoyageID and now specific pickup and delivery expected dates * a rejected order has its state updated to rejected. This enables the requester to modify the order, suggesting different required dates or locations and trigerring a new search for a voyage meeting the modified requirements. * booked orders now have a specific schedule from the booked voyage of when they will need a container allocated for their use * A Containers: needEmpty event is emitted to get a specific container allocated for use by the booked shipment The containers-comand-ms subscribes to Containers: needEmpty events and allocates an available container for each one * This microservice is maintaining a list of all containers and their current states * For each incoming needEmpty event, it assigns a free container to that order and emits an Orders: allocatedContainer event specifying the containerID of the allocated container. * It is very natural/necessary for the allocation of a container to be reported as an asynchronous event since this may occur at any time before the container is needed, possibly significanly later that he Containers:needEmpty event occurs * We make Orders: allocatedContainer an event on the Orders topic since that is the most significant state change which it drives. The orders-command-ms subscribes to all Orders: allocatedContainer events and updates the order current state with its allocated containerID * Once an rder is booked on a voyage and has a container allocated for it to use, the actual physical process of shipment canbegin at this point. * Since the delivery of empty container, loading it with goods at the pick up site, truck operations to get it to dockside etc are out of scope for this build, we can consider the container ready for its voyage at this point. Hence the Voyages:fullContainerReady event is emitted at this point by the orders-command-ms. This event includes the containerID of the allocated container. The voyages-command-ms subscribes to Voyages: fullContainerReady events an uses these to construct a complete manifest - the list of pairs which will travel on this voyage At this point the voyage-command-ms interacts with the fleet/ships-simulation-ms to simulate start of voyage * we have shown this in the figure as a syncronous call to getNextVoyageInfo . This oul also be handled with one or more event interactions * the ship-simulator-ms will update the state of this ship to show the available containers and orders on board * it will start the simulation of the ship moving on its course tocomplete the vogage * the ship-simulator-ms willemit a Voyages: ShipStartedVoyage event the Voyages-command-ms receives this event and for each order/container in the manifest emits an Orders: ContainerOnShip event the orders-command-ms will subscribe to Orders: ContainerOnShip events and update the current state of each identified order with this information. Command microservice interaction - container on ship at sea through shipment complete The diagram below shows all command interactions from container on ship in voyage through shipment delivered and order completed. As in the previous interaction diagram, the columns with grey/shaded processing blocks show work by (1) orders-command-ms (2) voyages-command-ms (3) containers-command-ms and containers-streaming-ms (4) fleet/ships-simulator service respectively. This diagram starts with containers on board a ship which is sailing on specific voyage and is at sea. The fleet/ships-simulator-ms repeatedly simulated movement of the ship along its course * It t emits Ships: GPSposition events recording the position of the ship at different points in simulated time. Similarly, while the ship is at sea, the contaner-streams-svc is continualy simulating temperature within the container and edge monitoring to adjust controls if necessary and to report a cold chain breach in that container if it occurs. * This will result in a repeated stream of Containers: tempAndGpsState events reporting the temperature, GPS coordinates and possibly power consumption of the container * There could also be on or more Containers: action events to adjust or reset controls of the refrigeration unit in the container * These adjustment event are initiated by predictive real-ime analytics on the cntainer state * If the temperature in the container goes out of range and there is a cold chain failure, a Containers: temperature Out of Range event is emitted After some period of simulated time tracked by these ship position and container state repeated events, the ship will be simulated as arriving at the destination port of the voyage. * The ship-simulator-ms emits a Voyages: ShipEndedVoyage event The voyages-command-ms subscribes to Voyages: ShipEndedVoyage and for each such event, emits Orders: containerOffShip * It can do this because the current state record for each voyage includes the manifest of pairs which travelled on that voyage * the current state of the voyage is updated to COMPLETED The orders-command-ms subscribes to Orders: containerOffShip and updates the the state of all orders which have completed their shipping leg as a result of completion of their booked voyage * Now, since simulation of the dockside unloading, customs processes, trucking operation to support deliver are out of scope for this build, we can consider the shipment delivered at this point * orders-command-ms emits Orders: containerDelivered and marks this as currnet state of container * With the shipment delivered, there is no further need for a container to be associated with this order; orders-command-ms emits Containers: containerReleased The containers-command-ms subscribes to Containers: cntainerReleased and marks the ciurrent state of the identified container as FREE and available to be allocated to other shipment orders The order-command-ms considers process of the shipmentorder complete at this point * It emits Orders: orderComplete and marks this as the current state of the order * A more complete and realistic build would statr invoicing and billing event at this poitn , but this was decided to be out of scope at this point The fleet/ships-simulator-ms will continue at this point to start the next voyage in its planned itenerary and interact with voyages-command-ms to do this * this is a cycled repetition of start of voyage interaction discussed previously Query microservice service - CQRS Order and Shipment tracking microservices The diagram below shows all interactions with the shipment tracking microservice. This microservice subscribes to may events carrying required information and supports one or more query APIs for different flavors of order and shipment tracking There could be multiple flavors of orderand shipment tracking query APIs supported: Order confirmation query could address orders, bookings, rejections, modified orders etc Shipment state query could cover: container assignment, on board ship, ship position, off ship, delivery, etc * Cold chain certification query could want to augment the above with a full temperature log of the container while in transit and expect reporting on temperature range violations. Since we are using a CQRS approach, and all queries are non state changing, we could combine these multiple query levels into a single microservice or separate them out into separate microservices. If query load is intense there could be multiple instances of each such query microservices with load balancing of user requests. The design of these different flavors query services is essentially the same. The internal state data to respond to queries is obtained by subscribing to the necessary Topics. Fofulel cold chain and shipment reporting, this will involve all four topics Orders, Voyages, Containers and Ships. Internally the data will be organized (1) by requester of the order, then by orderID, then current state and possibly summaries of repeated event history. The inteaction digram 3 above illustrates this organization. For any order and shipment tracking query service there are synchronous APIs offered at one side and subscribed events received at the other to gather required state information from the vent backbone. Topics, event types and the event emit and consumption lists From the interaction diagrams we can compile a list of all event types which will occur in the build and check that they are organized into topics in a way which preserves all essential event sequencing. The diagram below lists the event types and topics, showing emitters ( publishers) and consumers ( subscribers) of each event type. Step4 - data recovery considerations for this demonstration build At this point the pattern for data recovery after a microservice failure is understood in principle, but specific recovery demonstration after a failure is out of scope at this point.","title":"From Analysis to Microservice Specifications"},{"location":"analysis2microsvcs/#from-analysis-to-microservice-specifications","text":"","title":"From Analysis to Microservice Specifications"},{"location":"analysis2microsvcs/#goals-and-outline-of-section","text":"This section describes the design step which uses output from the event storming session and subsequent analysis and derives a set of micro services design specification. The goals for ts design step and the resulting specifications are: Highly modular cloud native microservices Event coupled microservices - facilitating independent modification and evolution of each microservice separatelys Allow for event sourcing \u2013 eventual correctness and recovery using event base) Illustrate CQRS and its scaling advantages Since we are delivering a demonstration application there will be some simulator / scaffolding / testing services mixed in with the required business processing. This is a common occurrence in agile development and it may be helpful to show how decision to scope and simplify a particular build and test step interact with decisions relating strictly to microservices design. Requirements for scalability, coupling of microservices only through the event back bone and eventual correctness differentiate this step from previous Event Storming and Domain Driven Design activities which were 100% business requirement driven.","title":"Goals and outline of section"},{"location":"analysis2microsvcs/#starting-materials-generated-during-event-storming-and-analysis","text":"In this microservices specification step we make use of the following materials generated during Event Storming and analysis of the Container Shipment example problem: Event Sequence flow Events \u2013 business description Critical events Aggregates and services * Users \u2013 roles user stories * Commands * Event linkages * Policies * Event prediction and probability flows * Data ( Conceptual ) The derivation of these material was described in: Analysis .","title":"Starting materials generated during Event Storming and Analysis"},{"location":"analysis2microsvcs/#event-linked-microservices-design-structure","text":"A complete microservices specification ( the target of this design step ) will include specifications of the following: Event Topics * Used to configure the Kafka Event Backbone Event types within each event topic Microservices: * These are finer grained than aggregates * May separate query and command; possibly multiple queries * May Separate whether simulation or business processing component * Demonstration Control \u2013main UI * Scaffolding and testing services - whether local and cloud versions Microservice specification ( for each identified * Data within Each microservice * APIs ( Synchronous ) * Topics and events Subscribed to * Events published / emitted List of end to end interactions * List of logic segments per microservice Recovery processing, scaling * We expect this to be highly patterned and template driven not requiring example-specific design With the above information coding of each microservice and other components of the sprint should be straightforward.","title":"Event linked microservices design - structure"},{"location":"analysis2microsvcs/#steps-in-the-design-process","text":"Here we describe in generic terms, each step in the process of deriving event-linked microservice specification. In following section we will describe in more detail how each of these steps plays out in the specific context of the the container shippment example.","title":"Steps in the design process"},{"location":"analysis2microsvcs/#list-of-generic-steps","text":"Step 1 - limit the context and scope for this particular build / sprint we assume that we are developing a particular build for a sprint within some agile development ; additional functions and complexity may be added in later sprints working from the initial list of aggregates, select which aggregates will be included in this build for each aggregate possible choices are: (1) to completely skip and workaround the aggregate in this build (2) to include a full lifecycle implementation of the aggregate (3) to provide a simplified lifecycle implementation - typicall a table of entities is initialized at s. tart up, and state changes to existing entities are tracked determine whether there are simulation services or predictive analytics service to be included in the build identify the external query apis and command apis which this build will support create entity lifecycle diagrams for entites having a full lifecycle implementation in this build / sprint . Step 2 - identify specific microservices in each aggregate each aggregate will be implemented as some composition of (1) a command microservice managing state chsnges to the entities in this aggregate (2) possibly one or more separate ( CQRS) query services providing internal or external API query capabilities (3) additional simulation, predictive analytics or User Interface microservices The command microservice will be built around and manage a collection of active entites for the aggregate, keyed by some primary key The separation of each aggregate into specific component microservices as outlined above, will be a complete list of microservices for the build / sprint. Identify the data collections, and collection organization (keying structure) in each command and query microservice for this build. Step 3 - generate microservice interaction diagrams for the build The diagram will show API calls initiating state change It shows for each interaction whether this is a synchronous API calls or an asynchronous event interaction via the event backbone The diagram labels each specific event interaction between microservices trigerring a state change ( Typically queries are synchronous API calls since the caller cannot usefully proceeed until a result is returned ) From this we can extract: (1) a complete list of event types on each topic, with information passed on each event type (2) the complete list of \u201clogic segments\u201d for each microservice processing action in response to an API call or initiating event When, at the next level of detail, the individual fields in each event are specified and typed, the CloudEvents standard in https://github.com/cloudevents/spec should be assumed as a start point Step 4 - specify recovery approach in case a microservice fails If a microservice fails it will need to recover its internal state date by resubscribing to one or more topics on the event bus In general, commamd and query microservices will have a standard pattern for doing this Any custom event filtering and service specific logic should be specified","title":"List of generic steps:"},{"location":"analysis2microsvcs/#concepts-and-rationale-underlying-this-design-approach","text":"What is the difference between event information stored in the event backbone and state data stored in the microservices ? the event information stored persistently in the event backbone is organized by topic and, within each topic, entirely by event time-of-occurrence. the state information in a command microservice is a list (collection) of all currently active entities of the owning aggregate ( e.g. all orders, all voyages etc ) and the current state of each such entity each command microservice will consist of a collection of entity records keyed by primary key this is complementary to the historically organized information in the event backbone. When is it OK to be using synchronous interactions between services instead of asyncrhonous event interacts through the event backbone? For non-state-changing queries, for which the response is always instantaneously available a synchronous query callmy be Ok and will provide a simpler more understandable interface. Any processing which can be though of as being triggered by some state change in anothe aggregate should be modelled with an asynchronous, because as the solution eveolves other new microservices may also need to be aware of this event. We do not want to have to go back and change logic n the service where this event originated to have that microservice actively report the event to all potential consumers. How do we save microservices from having to maintain data collections with complex secondary indexing for which eventual consistency will be hard to implement? Each command microservice should do all its state changing updates using the primary key lookup only for its entities. Each asynchronous event interaction between microservices should carry primary entityIds ( orderID, VoyageID, shipID) for any entities associated with the interaction. Each query which might require speciaoized secondary indexing to respond to queries can be implemented in a separate CQRS query service which subscribes to events to do all internal updating and receives events from the event backbone in a ( Consistent) eventually correct order. This allows for recovery of any failed service by rebuilding it in \"eventually correct\" order.","title":"Concepts and rationale underlying this design approach"},{"location":"analysis2microsvcs/#specific-application-to-container-shipment-example","text":"In this section we discuss how the generic steps introduced above can be applied for the Container shipping example","title":"Specific application to Container Shipment example"},{"location":"analysis2microsvcs/#step1-context-and-scope-for-demonstration-build","text":"An initial scoping decision is that the demonstration will address shipment orders and shipment progress initiated by the \"manufacturer\" of the goods with the shipment company. In the context of the example there is also discussion of manufacturer and retailer reaching some agreement on the goods to be delivered but this is not part of the demonstrated capabilities. The Event Storming analysis of the shipment problem was end-to-end and involved many aggregates including: Orders, Voyages, Trucking operations both at the source (maufacturer pickup ) and destination (retailer delivery), Customs and export interactions, Container loading into ship at source port and unloading from ship at destination port, containers and fleet of ships. To have a simple initial demonstration build showing the role of EDA architecture and event coupled microservices, as an initial step towards development of a more complete system using agile incremental development and deployment, the initial demonstration build makes the following simplifications and scoping decisions: This build will have no implementation of: Trucking operations, Customs and export, or Dockside Handling aggregates It will show a full lifecyle for a manufacturer user to place an order for shipment, seeing a filled container placed on board ship transported to the destination port and delivered. It will include a simulation Service for ship movements - tracking the movement of ships carrying containers It will include simulation and analytics for Container temperatures in while onboard ship * It will provide a query for a user to track an order and the current location and state of the associated shipment Based on the scope selection above, active aggregates in the build will be: Orders - with support for a complete order lifecycle Voyages - list of planned port to port passges with dates and manifests for each sip Containers - with allocation of a container to each order and temperature tracking of refrigerated containers Ships - with tracking of current voyage and current geographical position of each container ship The event backbone will be configured with a topic for each of the above aggregated. We expect to see multiple event typs on each topic, but subscriptions and sequencing of events will be within these high level topics. Command API.s will be provided to: place a new shipment order track an existing order, eith to confirmits booking state or to resolve the actual location and status of the container in transit * modify an order request which could not be booked within the requested time window A more complete and complex build could include an api for a shipping company person to optimally and manually assign orders to voyages, but for this initial demonstration we will automate this process and assign orders automatilly to the first voyage found meeting the requested requirements. Specifically, each order is assigned to the first located voyage: going from the port nearest to pickup location to the port nearest the delivery location, within the requested time window for pickup and delivery with available capacity for an additional container on that voyage. Additional APIwill be need: to initiate the overall demonstration to manage and view specific simulation component - container simulation and analytics abd ship simulation and analytics.","title":"Step1 - context and scope for demonstration build"},{"location":"analysis2microsvcs/#shipment-order-lifecycle-and-state-change-events","text":"The scoping decisions for the demonstration build listed above are reflected in a shipment order life cycle diagram shown below. A shipment order is initially created with an API call made by a manufacturer. The order request specifies: the pickup location where emptry container will be loaded the delivery location where the container is to be delivered to (we expect this to be in a remote country requiring a sea voyage ) * the shipment time window i.e. * earliest date at which goods are available at pickup location for loading into the container * date by which delivery to the destination address is required Since our initial demonstration build expects to show refrigeration behavior snd track preservation of a cold chain, we asume that orders are for some commodity which requires refrigeration during its shipment. A graphical view of this API with some additional field specification is provided in Create order Request . When a new shipment order is placed, the shipping company must determine whether there is available capacity in some planned ship voyage which meets all the requirements specified by the manufacturer / customer. If there is a planned voyage with available cpacity for ne additional container going from the source port nearest the pickup location to the destination port nearest to the delivery location then the order can transition to state=BOOKED and positive confirmation of the order returned to the requester. If no such voyage is available then the shipment order transitions to state=REJECTED(No Availability) and this is reported back to the requester. Once an order is BOOKED, then the expected dates and locations where for which a container will be needed are known. A request can be issued to book a specific (refrigerated) container for use with this shipment. We assume that the shipping company always has enough container available to meet expected shipment demand, hence the shipment order will transition to state=CONTAINER_ALLOCATED when this container booking is received. Since the scope for this demonstration build excliuded the simulation of trucking operations to get the goods from the manufacturer's pickup location, export clearance and actual dockside loading operations, once an order has a container allocated it is \" ready to go\" and transitions to state=FULL_CONTAINER_VOYAGE_READY. The actual event of recording the container as being on board ship and at sea will not happen until simulated time in the demonstration reaches the scheduled start of the voyage on which that container is booked and the container ship assigned to that voyage is in the source port and also ready to go. At that point in simulated time, the state of the shipment order changes from state = FULL_CONTAINER_VOYAGE_READY to state = CONTAINER_ON_SHIP. While the order has state = CONTAINER_ON_SHIP, then we will be receiving temperature information from the COntainer simulation and analytics and Ship position information from the ship simulation service. Both provide a continuous streaming souces of information which should be considered part of the extended shipment state. After some period of simulated time, the ship will reach the destination port of the voyage. at this time the Oder transitions to state = CONTAINER_OFF_SHIP since our scope excluded simulation of actual dockside unloading information. Since we are not modelling customs clearance or trucking operations, there are no further events to be modelled until the order state = CONTAINER_DELIVERED. Since we are not modelling invoicing and billing operations the Container can be deallocated from this order and retruned to some pool of free containers. When that has occurred the oder state can be considered state = ORDER_COMPLETED. We have described the the mornal, exception-free path first. There are two exception cases modelled. At the time a new shipment order is requested, there may be no voyage with available capacity meeting the location and time requirements of the request. When this occurs, the manufacturer/user is informed and the order state becomes state= REJECTED (No Availability). At this point the user can modify the order with a second API requests changing dates or possibly locations. This retry request could still fail returning the order back to state = REJECTED ( No availability). Alternatively the changes in dates and location could be anough for an available voyage to be found. When this occurs the order will transition to state = BOOKED modified. * If an API call to modify an order is made and the order is in some state different from state=REJECTED(No availability), we reject the API request. There could be race conditions, the order is in the process of being assigned to a voyage, or complex recovery issues, - what if the order is already in a container and at sea when a modify order is received ? Full treatment of these complex business specific issues is out of scope and avoided by the state check in the modify order call API call We also model the exception condition when the refrigeration unit in a container fails or is misset or over loaded. If the temperature in the container goes outside the service level rance for that shipment the goods must be considered spoiled. The oreder will transition from state = CONTAINER_ON_SHIP to state = ORDER_SPOILED(Temperature out of Range). Some complex business recovery such as compensating the customer and possibly scheduling a replcement shipment may be required. The details will be contract specific and outside the scope , but we do include the use of Streaming event container analytics to detect the spoilage and use rule based real-time /edge adjustments of the refrigeration gear to avoid spoilage in the demonstration simulation.","title":"Shipment order lifecycle and state change events"},{"location":"analysis2microsvcs/#step-2-microservices-and-microservice-owned-data-for-demonstration-build","text":"In this step we fix the specific microservices for each aggregate and te data organization for each microservice.","title":"Step 2 -  microservices and microservice owned data for demonstration build"},{"location":"analysis2microsvcs/#orders-aggregate","text":"For Orders we will need an orders-command-ms which will maintain a list of all current active orders and the current state of each order. The order state will as described above. The collection of active orders will be keyed by orderID. The orders-command-ms will offer APIs for create order and modify order since these are external interactions. It makes sense to use CQRS and separate out order tracking into a separate oders-query-ms since: The demand for order tracking might have significantly more intense scalability needs than order commands * orders are typically created once and changes state a handful of times; there could be many different users querying status of a particular orders independently and each requesting tracking multiple time for each order to determine if there is some delay expected Order state tracking information should probably be organized by requesting customer NOT bu order ID * since customers should be ollowed to see status on their own orders but not on other customer's orders * when the shipping company is tracking an order it is most frequently doing so on behalf of a specific customer With this approach orders-query-ms becomes a CQRS query service with internal state updated from the event backbone, and an order tracking API","title":"Orders Aggregate"},{"location":"analysis2microsvcs/#voyages-aggregate","text":"For Voyages we will need a voyages-command-ms which will maintain a list of all voyages and their current state. In any given run of the demonstration we will work with a fixed set of voyages - effectively the schedule for the container fleet - so there is no need for an API t create additional voyages. The voyage definition will be read from file when the build is initializing. We expect this voyage data to be well formed: each voyage has a container ship in the fleet allocated to make the voyage the voyages assigned to any one ship are properly \"chained\". For the sequence of voyages assigned to any one container ship, the destination port of the nth voyage is always the start port of the (n+1)th voyage The states of a yoyage are: SCHEDULED - in this state it can accept order bookings, knows how much free space is available for additional bookings, and knows the orderIDs of each shipment already booked on the voyage IN_PROGRESS - in this state it includes a manifest a list of the orderIDs and containerIDs on board the ship * COMPLETED - a voyage in the completed state supports tracing continers, may know which containers in the voyage were spoiled etc It will be helpful for the voyage-command-ms to include a query service to lookup voyages with a particular source port and destination port in a particular time windaw. This will help process booking request event but does not need to be an external API hence there is no strong argument for realizing this as a separate CQRS query service.","title":"Voyages Aggregate"},{"location":"analysis2microsvcs/#containers-aggregate","text":"For Containers we will need we will use a containers-command-ms to maintain a list of defined containerIDs and track the state of each container. A fixed set of valid container IDs will be initialized at demonstration start time. As noted previously we will assume this to be enough for all requested orders to be assigned a container without availability issues. Since the collection of containers is fixed the component will not need a cmmand API The container current state maintained in container-command-ms is: state = FREE - this container is not in use and is available to be assigned to a new shipment order state = ALLOCATED - thei container is allocated ot order orderID and potentially in use for that shipment We will be modelling and performing streaming analytics on temperature inside a (refrigerated) container. Hence there will be a separate services performing this streaming analytics and simulation: container-streaming-svc. Conceptually, while a container is ALLOCATED to a shipment order with state = CONTAINER_ON_SHIP, its internal temperature and power usage will be maintained as streaming state by the container-streaming-svc.","title":"Containers Aggregate"},{"location":"analysis2microsvcs/#fleetships-aggregate","text":"For Ships we wil have a monolithic fleet simulation service providing continuous simulation of ship position for each ship and modelling of ship events. This service will include a UI to enable viewing the positions and states of the ships. It may have a separate UI to control the overall demonstration. There is no requirement for any separate microservice maintining additional information on ship state.","title":"Fleet/Ships Aggregate"},{"location":"analysis2microsvcs/#step3-specifing-all-interactions-in-a-logic-flow-for-the-demonstration-build","text":"Using the understanding of the event flow from the Event Storming session, the scoping of this build, the list of microservices and data within each microservices developed in the steps above, we can write out in a complete interrraction flow. This flow illustrates how the microservices are linked together via the Event backbone using event interractions for all non API interractions between distinct microservices.","title":"Step3 - specifing all interactions in a logic flow for the demonstration build"},{"location":"analysis2microsvcs/#command-microservice-interactions-order-create-through-voyage-start-with-container-on-board","text":"The diagram below shows all command interactions from initial order creation through voyage start. The grey(shaded) columns of processing blocks are organized to show processing by the different command microservices. Column 1 shows processby the orders-command-ms Column 2 shows processing by the voyages-command-ms Column 3 shows processing by the containers-command-ms and in a later figure by containers-streaming-ms Column 4 shows processing by the fleet/ships-simulator-ms Comments on steps in the command flow: A new shipment order request is initiated with the syncronous createOrder API at top left * the orders-command-ms will create a new order record in its tale of active orders and populate it with order details * a NewOrder event is emitted on the Orders Topic * the generated orderID or the new shipment order is returned to the requester in the createOrder response. This enables the requester to query the status of an order and possibly modify the parameters of an unbooked order. * the voyages-command-ms subscibes to all newOrder events on the Orders topic and tries to assign each new order to an available voyage * this operation is simplified by internally maintainin some list of vayages organized by port pait ( Starting port - ending port combination) and by time within port pair. * using such a list each voyage matching the port pair requirement of the new order can be checked or available capacity * if a voyage meeting all requirements for the new order is found, a booking event is emitted; if not, a rejected(No availability) event is emitted * a booked event causes state change in both the voyage - available capacity reduced, new order added to bookings - and to the order. We choose to make both booking and rejected (no Availabiity) events on the Orders topic rather than the Voyages topic the orders-command-ms subscribes to Orders: booking and to Orders: Rejected(no availability) events and updates the current state of the affected order with the received information. * for bookings, the current state of order is updated with the booking informationg including VoyageID and now specific pickup and delivery expected dates * a rejected order has its state updated to rejected. This enables the requester to modify the order, suggesting different required dates or locations and trigerring a new search for a voyage meeting the modified requirements. * booked orders now have a specific schedule from the booked voyage of when they will need a container allocated for their use * A Containers: needEmpty event is emitted to get a specific container allocated for use by the booked shipment The containers-comand-ms subscribes to Containers: needEmpty events and allocates an available container for each one * This microservice is maintaining a list of all containers and their current states * For each incoming needEmpty event, it assigns a free container to that order and emits an Orders: allocatedContainer event specifying the containerID of the allocated container. * It is very natural/necessary for the allocation of a container to be reported as an asynchronous event since this may occur at any time before the container is needed, possibly significanly later that he Containers:needEmpty event occurs * We make Orders: allocatedContainer an event on the Orders topic since that is the most significant state change which it drives. The orders-command-ms subscribes to all Orders: allocatedContainer events and updates the order current state with its allocated containerID * Once an rder is booked on a voyage and has a container allocated for it to use, the actual physical process of shipment canbegin at this point. * Since the delivery of empty container, loading it with goods at the pick up site, truck operations to get it to dockside etc are out of scope for this build, we can consider the container ready for its voyage at this point. Hence the Voyages:fullContainerReady event is emitted at this point by the orders-command-ms. This event includes the containerID of the allocated container. The voyages-command-ms subscribes to Voyages: fullContainerReady events an uses these to construct a complete manifest - the list of pairs which will travel on this voyage At this point the voyage-command-ms interacts with the fleet/ships-simulation-ms to simulate start of voyage * we have shown this in the figure as a syncronous call to getNextVoyageInfo . This oul also be handled with one or more event interactions * the ship-simulator-ms will update the state of this ship to show the available containers and orders on board * it will start the simulation of the ship moving on its course tocomplete the vogage * the ship-simulator-ms willemit a Voyages: ShipStartedVoyage event the Voyages-command-ms receives this event and for each order/container in the manifest emits an Orders: ContainerOnShip event the orders-command-ms will subscribe to Orders: ContainerOnShip events and update the current state of each identified order with this information.","title":"Command microservice interactions - order create through voyage start with container on board"},{"location":"analysis2microsvcs/#command-microservice-interaction-container-on-ship-at-sea-through-shipment-complete","text":"The diagram below shows all command interactions from container on ship in voyage through shipment delivered and order completed. As in the previous interaction diagram, the columns with grey/shaded processing blocks show work by (1) orders-command-ms (2) voyages-command-ms (3) containers-command-ms and containers-streaming-ms (4) fleet/ships-simulator service respectively. This diagram starts with containers on board a ship which is sailing on specific voyage and is at sea. The fleet/ships-simulator-ms repeatedly simulated movement of the ship along its course * It t emits Ships: GPSposition events recording the position of the ship at different points in simulated time. Similarly, while the ship is at sea, the contaner-streams-svc is continualy simulating temperature within the container and edge monitoring to adjust controls if necessary and to report a cold chain breach in that container if it occurs. * This will result in a repeated stream of Containers: tempAndGpsState events reporting the temperature, GPS coordinates and possibly power consumption of the container * There could also be on or more Containers: action events to adjust or reset controls of the refrigeration unit in the container * These adjustment event are initiated by predictive real-ime analytics on the cntainer state * If the temperature in the container goes out of range and there is a cold chain failure, a Containers: temperature Out of Range event is emitted After some period of simulated time tracked by these ship position and container state repeated events, the ship will be simulated as arriving at the destination port of the voyage. * The ship-simulator-ms emits a Voyages: ShipEndedVoyage event The voyages-command-ms subscribes to Voyages: ShipEndedVoyage and for each such event, emits Orders: containerOffShip * It can do this because the current state record for each voyage includes the manifest of pairs which travelled on that voyage * the current state of the voyage is updated to COMPLETED The orders-command-ms subscribes to Orders: containerOffShip and updates the the state of all orders which have completed their shipping leg as a result of completion of their booked voyage * Now, since simulation of the dockside unloading, customs processes, trucking operation to support deliver are out of scope for this build, we can consider the shipment delivered at this point * orders-command-ms emits Orders: containerDelivered and marks this as currnet state of container * With the shipment delivered, there is no further need for a container to be associated with this order; orders-command-ms emits Containers: containerReleased The containers-command-ms subscribes to Containers: cntainerReleased and marks the ciurrent state of the identified container as FREE and available to be allocated to other shipment orders The order-command-ms considers process of the shipmentorder complete at this point * It emits Orders: orderComplete and marks this as the current state of the order * A more complete and realistic build would statr invoicing and billing event at this poitn , but this was decided to be out of scope at this point The fleet/ships-simulator-ms will continue at this point to start the next voyage in its planned itenerary and interact with voyages-command-ms to do this * this is a cycled repetition of start of voyage interaction discussed previously","title":"Command microservice interaction - container on ship at sea through shipment complete"},{"location":"analysis2microsvcs/#query-microservice-service-cqrs-order-and-shipment-tracking-microservices","text":"The diagram below shows all interactions with the shipment tracking microservice. This microservice subscribes to may events carrying required information and supports one or more query APIs for different flavors of order and shipment tracking There could be multiple flavors of orderand shipment tracking query APIs supported: Order confirmation query could address orders, bookings, rejections, modified orders etc Shipment state query could cover: container assignment, on board ship, ship position, off ship, delivery, etc * Cold chain certification query could want to augment the above with a full temperature log of the container while in transit and expect reporting on temperature range violations. Since we are using a CQRS approach, and all queries are non state changing, we could combine these multiple query levels into a single microservice or separate them out into separate microservices. If query load is intense there could be multiple instances of each such query microservices with load balancing of user requests. The design of these different flavors query services is essentially the same. The internal state data to respond to queries is obtained by subscribing to the necessary Topics. Fofulel cold chain and shipment reporting, this will involve all four topics Orders, Voyages, Containers and Ships. Internally the data will be organized (1) by requester of the order, then by orderID, then current state and possibly summaries of repeated event history. The inteaction digram 3 above illustrates this organization. For any order and shipment tracking query service there are synchronous APIs offered at one side and subscribed events received at the other to gather required state information from the vent backbone.","title":"Query microservice service  - CQRS Order and  Shipment tracking microservices"},{"location":"analysis2microsvcs/#topics-event-types-and-the-event-emit-and-consumption-lists","text":"From the interaction diagrams we can compile a list of all event types which will occur in the build and check that they are organized into topics in a way which preserves all essential event sequencing. The diagram below lists the event types and topics, showing emitters ( publishers) and consumers ( subscribers) of each event type.","title":"Topics, event types and the event emit and consumption lists"},{"location":"analysis2microsvcs/#step4-data-recovery-considerations-for-this-demonstration-build","text":"At this point the pattern for data recovery after a microservice failure is understood in principle, but specific recovery demonstration after a failure is out of scope at this point.","title":"Step4 -  data recovery considerations for this demonstration build"},{"location":"demo/","text":"Demo Script This demo script is using the localhost deployment with a mapping of the host name kcsolution to localhost defined in the /etc/hosts file. For IBM Cloud change the hostname accordingly. Here is how to execute the business process step by step: Step 1: Manufacturer create an order: Go to the http://kcsolution:3110 URL to access the demonstration home page: This page presents the process and some tiles that can be used to simulate the progression within the business process. The grey shadowed tiles are not actives. From the Initiate Orders - Manufacturer we can have the manufacturer creating a new fresh product order to ship over sea. To represent different manufacturer the first select box is used to support different scenarios in the future. GoodManufacturer can be used. Then a list of existing orders may be displayed. You can add order with the UI, but you can also use a script in the order command microservice project: https://github.com/ibm-cloud-architecture/refarch-kc-order-ms/blob/master/order-command-ms/scripts/createOrder.sh Here is an example to add an order to get a voyage from Oakland to Shanghai: ./createOrder.sh localhost:10080 ./orderOacklandToChinaCreateonso There is a lot happening here. The Angular is getting orders using the orders.service.ts service from the BFF at the address: http://localhost:3010/api/orders . The BFF is calling the Order Query Microservice via a javascript client code: getOrders(manuf) function. . The Order Query microservice URL is defined in environment variable or defaulted in the config file. It is mapped to the deployed Order service. (e.g. http://ordercmd:9080/orders) Selecting one order using the Arrow icon open the details of the order: As illustrated in the CQRS diagram: the creation of the order goes to the order command microservice which publishes a OrderCreated event to the orders topic and then consumes it to persist the data to its database. See source code here If you plug a orders consumer you can see the following trace wiht the status of the order being pending and the type of event being OrderCreated {\"payload\":{ \"orderID\":\"1fcccdf2-e29d-4b30-8e52-8116dc2a01ff\", \"productID\":\"Carrot\", \"customerID\":\"GoodManuf\", \"quantity\":10000, \"pickupAddress\": \"...\", \"expectedDeliveryDate\":\"2019-03-31T13:30Z\", \"status\":\"pending\"}, \"type\":\"OrderCreated\", \"version\":\"1\"} Step 2: K Container Shipment Manager looking at Orders From the home page goes to the Shipment Inc tile: Then the home page lists the current order the shipment company received The status of those events will be modified over time while the order is processed down stream by the voyage and container services. The following sequence diagram illustrates the flow: Looking at the traces in the voyage service voyages_1 | emitting {\"timestamp\":1548788544290,\"type\":\"OrderAssigned\",\"version\":\"1\",\"payload\":{\"voyageID\":100,\"orderID\":\"1fcccdf2-e29d-4b30-8e52-8116dc2a01ff\"}} or at the orders topic: {\"timestamp\":1548792921679, \"type\":\"OrderAssigned\",\"version\":\"1\", \"payload\":{\"voyageID\":100,\"orderID\":\"1fcccdf2-e29d-4b30-8e52-8116dc2a01ff\"}} Step3: Simulate the ship in blue water From the home page goes to the Simulate the bluewater tile, then in the main page select one of the available fleet. Only the North Pacific has data as of now: The fleet panel lists the boats, their location and status and a map: Selecting one boat with the edit button, goes to the boat detail view: You can start the simulation on the ship movement by seleting one of the three pre-defined scenarios: Fire some containers One reefer down * Or boat going thru a heat waves The command is sent to the Simulator and the boat will start to move and generate container metrics: The simulation implementation is yet not completed.","title":"Demo Script"},{"location":"demo/#demo-script","text":"This demo script is using the localhost deployment with a mapping of the host name kcsolution to localhost defined in the /etc/hosts file. For IBM Cloud change the hostname accordingly. Here is how to execute the business process step by step:","title":"Demo Script"},{"location":"demo/#step-1-manufacturer-create-an-order","text":"Go to the http://kcsolution:3110 URL to access the demonstration home page: This page presents the process and some tiles that can be used to simulate the progression within the business process. The grey shadowed tiles are not actives. From the Initiate Orders - Manufacturer we can have the manufacturer creating a new fresh product order to ship over sea. To represent different manufacturer the first select box is used to support different scenarios in the future. GoodManufacturer can be used. Then a list of existing orders may be displayed. You can add order with the UI, but you can also use a script in the order command microservice project: https://github.com/ibm-cloud-architecture/refarch-kc-order-ms/blob/master/order-command-ms/scripts/createOrder.sh Here is an example to add an order to get a voyage from Oakland to Shanghai: ./createOrder.sh localhost:10080 ./orderOacklandToChinaCreateonso There is a lot happening here. The Angular is getting orders using the orders.service.ts service from the BFF at the address: http://localhost:3010/api/orders . The BFF is calling the Order Query Microservice via a javascript client code: getOrders(manuf) function. . The Order Query microservice URL is defined in environment variable or defaulted in the config file. It is mapped to the deployed Order service. (e.g. http://ordercmd:9080/orders) Selecting one order using the Arrow icon open the details of the order: As illustrated in the CQRS diagram: the creation of the order goes to the order command microservice which publishes a OrderCreated event to the orders topic and then consumes it to persist the data to its database. See source code here If you plug a orders consumer you can see the following trace wiht the status of the order being pending and the type of event being OrderCreated {\"payload\":{ \"orderID\":\"1fcccdf2-e29d-4b30-8e52-8116dc2a01ff\", \"productID\":\"Carrot\", \"customerID\":\"GoodManuf\", \"quantity\":10000, \"pickupAddress\": \"...\", \"expectedDeliveryDate\":\"2019-03-31T13:30Z\", \"status\":\"pending\"}, \"type\":\"OrderCreated\", \"version\":\"1\"}","title":"Step 1: Manufacturer create an order:"},{"location":"demo/#step-2-k-container-shipment-manager-looking-at-orders","text":"From the home page goes to the Shipment Inc tile: Then the home page lists the current order the shipment company received The status of those events will be modified over time while the order is processed down stream by the voyage and container services. The following sequence diagram illustrates the flow: Looking at the traces in the voyage service voyages_1 | emitting {\"timestamp\":1548788544290,\"type\":\"OrderAssigned\",\"version\":\"1\",\"payload\":{\"voyageID\":100,\"orderID\":\"1fcccdf2-e29d-4b30-8e52-8116dc2a01ff\"}} or at the orders topic: {\"timestamp\":1548792921679, \"type\":\"OrderAssigned\",\"version\":\"1\", \"payload\":{\"voyageID\":100,\"orderID\":\"1fcccdf2-e29d-4b30-8e52-8116dc2a01ff\"}}","title":"Step 2: K Container Shipment Manager looking at Orders"},{"location":"demo/#step3-simulate-the-ship-in-blue-water","text":"From the home page goes to the Simulate the bluewater tile, then in the main page select one of the available fleet. Only the North Pacific has data as of now: The fleet panel lists the boats, their location and status and a map: Selecting one boat with the edit button, goes to the boat detail view: You can start the simulation on the ship movement by seleting one of the three pre-defined scenarios: Fire some containers One reefer down * Or boat going thru a heat waves The command is sent to the Simulator and the boat will start to move and generate container metrics: The simulation implementation is yet not completed.","title":"Step3: Simulate the ship in blue water"},{"location":"design/","text":"Design considerations Microservices for shipment order handling In this section we provided additional explanations on the organization of the shipment handling processing into a set of EDA coupled microservices. This will include: some further explanation of the concept behind each of the proposed microservices user stories for the microservices * explanation how this uses and benefits from key EDA patterns - event sourcing and Command Query Responsibility Separation (CQRS). Orders Microservice: Place Shipment Order - user stories As a manufacturer of pharmaceutical goods with production location XXX near port UU, I repeatedly identify new potential retailers for my product - for example a retailer with a distribution hub at location YYY near port VV - and I need to place an order with shipping company (K.Containers) to have a container of my products picked up from location XXX and delivered to location YYY. At the time I request a shipment booking I always know: the pickup location XXX and its adjacent port UU the delivery location YYY and its adjacent port VV the earliest date at which a container's worth of my products could be available for pickup at XXX the latest date by which it needs to be delivered to my target retailer at location YYYY Here is an example of screen I may use: Since my product can degrade if exposed to extreme temperatures, I expect transport to be in a refrigerated container and can supply a specific temperature range to be maintained while my goods are in transit. If the shipping company (K.Containers) has no available capacity to ship a container meeting my timing and delivery requirements, I expect the order request to be rejected. This will enable me to consider other shipping arrangements or renegotiate dates with my target retailer. If the order can be placed, I will want the response from the shipping company (K.Containers) to include a committed reasonable price for the shipment to be specified. In addition, I would like to know on confirmation of the order: the expected pickup and delivery dates (this will help close my agreement with the proposed retailer receiving the goods) the identity of the ship and scheduled voyage which will transport my container (this will help me with insurance considerations) * an orderID which I can use with the shipping company subsequently to track the order In general any pickup any delivery dates after my product availability and before the customer required delivery date are acceptable. I know that I will be expected to document properties of my product including specifications of its nature and origin, weight transported, recipient for whom it is intended etc... for Customs and export processing and for possible use by the shipping company BUT is not essential for an initial implementation of the order placement microservice. Orders Microservice: Track Order user story As a manufacturer of Pharmaceutical goods who has placed a shipment order with a shipping company (K.Containers) and received an order ID for that shipment, I may repeatedly request for tracking in that orderID and expect to be told the current state and progress of the order. For tracking requests made before the goods are picked up from my facility, this will be primarily to confirm the order and to hear about any changes in expected pickup date or expected delivery date which could have resulted from delay of the assigned ship in earlier voyages or other difficulties. Having this information will help me maintain good relations with the target retailer expecting to receive the goods. For tracking requests made while my goods are in transit or have been delivered, I expect to receive full information of the history of the container carrying my goods including: whether it has been picked up from my manufacturing site XXX by trucking / land transport and delivered to source port UU whether it has been cleared for export and loaded onto the designated ship the location history of the ship if the ship has arrived at destination port VV, whether my goods are unloaded and cleared by customs whether a trucking / land transport has picked up the container and delivered to the retailer's location YYY a full temperature and gps history of the container for the complete transit end to end. Having this tracking information will give me confidence that my goods have not been damaged in transit and are or soon will be properly delivered to the expected recipient in good order. In an initial implementation of the track order microservice, some of this event information - particularly relating to customs, export, ship loading an unloading at port and trucking land transport operations may be missing. Order life cycle Voyages Microservice: Create new order and Assign to Voyage - user story As the person in Container Shipping company K.Containers reponsible for keeping track of shipment orders we have accepted and responded to customer order requests for new shipment orders, I need to be able to: determine reliably whether there is free capacity on a particular scheduled voyage to accomodate an additional container AND IF space is available on that voyage ... * create a unique new orderID for the shipment this shipment can be accepted * set up persistent information with the order which will help me ensure that shipment operations with K.Containers are properly set up for it. This will include: * the pick up location and port. * expected pickup date. * the delivery location and port. * the voyageID on which this container is now booked. * the shipID for that voyage. * associate this new orderID with the voyage. * decrement any free space count for that voyage. Know that a specific voyage can accomodate an additional container for a specific order allows me to respond positively to a customer request to place a new shipment order. Having an accurate free space count associated with each voyage will tell me when a voyage is fully booked and cannot accept any further orders. It will also warn me when a voyage is underbooked; using that information I can consider getting K.Containers to market additional capacity or lower its prices. Having a list of all booked orders on a voyage will enable me to generate a manifest of all containers expected or in transit on that voyage. This is required as part of the customs and export clearances and also for review and approval by ship operations to ensure that the cargo loading for this voyage is acceptable/safe. The attributes associated with new order are used to schedule and trigger and monitor: trucking operations, customs and export operations, pickup and delivery confirmations, ship load and unload operation. Voyage Microservice: find voyages for port pair and time interval - user story As the person in Container Shipping company, K.Containers, reponsible for keeping track of shipment orders we have accepted and responding to customer order requests for new shipment orders, I need to be able to query the voyages records to find a list of voyages for a specific port-pair, with source port loading after a specifed start date and destination port unloading before a specified end date. This is the set of voyages I need to check for available capacity (using created new order and assign to voyage) when trying to determine whether a new shipment request from a customer can be satisfied by K.Containers shipping or not. Fleets/Ships Microservice - concept This service keeps track of each of the container ships available for transporting containers. Each ship has a unique shipID. The information about each ship is kept in a keystore keyed by shipID. The ships may be organized into Fleets. A ship record is created when a new ship is commissioned, joins the fleet and becomes available to carry containers as part of the shipping service. We can think to this as being triggered by some \"New ship event\" on the event bus. Each ship record will carry attributes of the ship including its full name and registry. An important attribute from the point of view of processing shipment orders and quote requests is the carrying capacity of the ship. How many containers can it carry on any voyage? We can accept additional shipment bookings only for voyages where there will be space available to carry them on the ship. In addition to its ShipID Key and attributes including capacity (number of containers it is designed to carry). As part of the other important information is the events related to the ship to record things which have happened to that ship. This list will include: GPS lat/log position reports of the position of the ship a different points in time. Events of the ship starting or completing a specific scheduled \"voyage\" - sailing from source port to destination port as scheduled for this ship. Clearances for the ship to enter or leave territorial waters of a nation or port. Arrival at a port dock and start or completion of a ship load / load operation at the dock. Organizing the ship record in this way is an example of event sourcing ; all event relating specifically to a ship are saved. Using queries with time stamp, shipID it is possible to get a complete history of all events relevant to it. Voyages microservice - concept This service keeps track of each scheduled, current or completed voyage of a container ship, being loaded with containers at a source port, sailing to a destination port and having onboard containers unloaded there. The life cycle of a voyage is as follows: Voyages are scheduled some number of months in advance - typically in response to some predictive model for how much demand is expected for shipment taffic in the future for a specific source port destination port pair. * each voyage is assigned a unique voyageID at the time it is created. Each voyage is assigned to be handled by a specific ship, and will have expected dates for: * start and completion loading at the source port. * leaving the source port and travelling to the destination port. * arrival into unloading dock at the destination port and start and completion of unloading at that port. When a voyage is scheduled and before it is actually in progress, bookings (and cancellations) to carry containers can be accepted. * the capacity of the assigned ship determines the maximum number of containers which can be carried on the voyage; available capacity on the voyage must be tracked and booking accepted only until the voyage is fully booked When the expected source port loading date is reached and the voyage actually begins, there may be voyage events recording actual dates for arrival at the destination port etc..., which may be different from the expected dates. * since each ship is expecting to execute a sequence of voyages, delays on one voyage may force rescheduling expected dates or cancellations of follow on voyages. * A voyage is eventually completed. The voyage record, keyed by voyageID, will continue to be important for a while for auditing and billing activities but will eventually be archived. Voyage records play an important role in: * processing shipment quote requests - when could a container be delivered to this destination from this source? * processing a shipment order - when a container is actually booked for a specific voyage * providing a current manifest of which orders/containers are present or expected on the ship for a specific voyage Command Query Responsibility Separation (CQRS) may be important to the design of the voyage microservice to handling the processing above with ideal scalability and responsiveness. It is important that from the perspective of a single voyage, that at all time there is an accurate and reliable list of which orders have been accepted for the voyage and what is the ammount of capacity still available on that voyage for future bookings. Hence there needs to be an atomic method assign_order_to_voyage( ) which adds the order event to the voyage and decrements the free capacity count by one. Since this operation updates the voyage record, it is a command in the CQRS sense. When responding to a request for quote or getting a list of voyages which could be candidate placements for a booking, an important query is: Find_Voyages_With_Capacity() : i.e. find all voyages from source port A to destination port B .. which will leave the source port AFTER goods available date .. AND will arrive at destination port BEFORE goods delivery required date .. AND have bookable freespace Any such voyage can be used to respond to a quote or used as a target to try assigning a booking. If requests for shipment quotes are significantly more frequent than actual bookings, one could provide maximal scalability and rsponsiveness by doing a fully separated CQRS design. The actual table of voyages with accurate and realiable capacity counts for each voyage would be handled in an orders command service with n assign_Order_To_Voyage( ) command api. Requests to check for voyages likely to have availabity for a specific port piar in a specific time window, could be handled by a separate query service with voyage information indexed by port-pair and sorted by departure/arrival date. Whenever the Assign_Order_to_Voyage( ) command succeeds, it generates a new_order_booked event on the event bus. The Find_Voyages_with_Capacity( ) service subscribes to these events and uses them to keep its capacity information on each voyage approximately and eventually correct. This illustrates use of the CQRS pattern to allow the available space query service to be scaled over many processors while ensuring reliable processing of actual booking commands against individual voyages. In addition to capacity, each voyage record will maintin a list of all Orders assigned to to it, allowing generation of a full manifest for expected or actual contents of the ship. In the simplified example we are developing here, we do not worry about order cancellations or modifications; in a pratical production implementation the voyage record would also hold order cancel and order modify event using event sourcing to generate a reliable current manifest from the voyage event history. Read more on EDA design pattern...","title":"Design considerations"},{"location":"design/#design-considerations","text":"","title":"Design considerations"},{"location":"design/#microservices-for-shipment-order-handling","text":"In this section we provided additional explanations on the organization of the shipment handling processing into a set of EDA coupled microservices. This will include: some further explanation of the concept behind each of the proposed microservices user stories for the microservices * explanation how this uses and benefits from key EDA patterns - event sourcing and Command Query Responsibility Separation (CQRS).","title":"Microservices for shipment order handling"},{"location":"design/#orders-microservice-place-shipment-order-user-stories","text":"As a manufacturer of pharmaceutical goods with production location XXX near port UU, I repeatedly identify new potential retailers for my product - for example a retailer with a distribution hub at location YYY near port VV - and I need to place an order with shipping company (K.Containers) to have a container of my products picked up from location XXX and delivered to location YYY. At the time I request a shipment booking I always know: the pickup location XXX and its adjacent port UU the delivery location YYY and its adjacent port VV the earliest date at which a container's worth of my products could be available for pickup at XXX the latest date by which it needs to be delivered to my target retailer at location YYYY Here is an example of screen I may use: Since my product can degrade if exposed to extreme temperatures, I expect transport to be in a refrigerated container and can supply a specific temperature range to be maintained while my goods are in transit. If the shipping company (K.Containers) has no available capacity to ship a container meeting my timing and delivery requirements, I expect the order request to be rejected. This will enable me to consider other shipping arrangements or renegotiate dates with my target retailer. If the order can be placed, I will want the response from the shipping company (K.Containers) to include a committed reasonable price for the shipment to be specified. In addition, I would like to know on confirmation of the order: the expected pickup and delivery dates (this will help close my agreement with the proposed retailer receiving the goods) the identity of the ship and scheduled voyage which will transport my container (this will help me with insurance considerations) * an orderID which I can use with the shipping company subsequently to track the order In general any pickup any delivery dates after my product availability and before the customer required delivery date are acceptable. I know that I will be expected to document properties of my product including specifications of its nature and origin, weight transported, recipient for whom it is intended etc... for Customs and export processing and for possible use by the shipping company BUT is not essential for an initial implementation of the order placement microservice.","title":"Orders Microservice: Place Shipment Order - user stories"},{"location":"design/#orders-microservice-track-order-user-story","text":"As a manufacturer of Pharmaceutical goods who has placed a shipment order with a shipping company (K.Containers) and received an order ID for that shipment, I may repeatedly request for tracking in that orderID and expect to be told the current state and progress of the order. For tracking requests made before the goods are picked up from my facility, this will be primarily to confirm the order and to hear about any changes in expected pickup date or expected delivery date which could have resulted from delay of the assigned ship in earlier voyages or other difficulties. Having this information will help me maintain good relations with the target retailer expecting to receive the goods. For tracking requests made while my goods are in transit or have been delivered, I expect to receive full information of the history of the container carrying my goods including: whether it has been picked up from my manufacturing site XXX by trucking / land transport and delivered to source port UU whether it has been cleared for export and loaded onto the designated ship the location history of the ship if the ship has arrived at destination port VV, whether my goods are unloaded and cleared by customs whether a trucking / land transport has picked up the container and delivered to the retailer's location YYY a full temperature and gps history of the container for the complete transit end to end. Having this tracking information will give me confidence that my goods have not been damaged in transit and are or soon will be properly delivered to the expected recipient in good order. In an initial implementation of the track order microservice, some of this event information - particularly relating to customs, export, ship loading an unloading at port and trucking land transport operations may be missing.","title":"Orders Microservice: Track Order user story"},{"location":"design/#order-life-cycle","text":"","title":"Order life cycle"},{"location":"design/#voyages-microservice-create-new-order-and-assign-to-voyage-user-story","text":"As the person in Container Shipping company K.Containers reponsible for keeping track of shipment orders we have accepted and responded to customer order requests for new shipment orders, I need to be able to: determine reliably whether there is free capacity on a particular scheduled voyage to accomodate an additional container AND IF space is available on that voyage ... * create a unique new orderID for the shipment this shipment can be accepted * set up persistent information with the order which will help me ensure that shipment operations with K.Containers are properly set up for it. This will include: * the pick up location and port. * expected pickup date. * the delivery location and port. * the voyageID on which this container is now booked. * the shipID for that voyage. * associate this new orderID with the voyage. * decrement any free space count for that voyage. Know that a specific voyage can accomodate an additional container for a specific order allows me to respond positively to a customer request to place a new shipment order. Having an accurate free space count associated with each voyage will tell me when a voyage is fully booked and cannot accept any further orders. It will also warn me when a voyage is underbooked; using that information I can consider getting K.Containers to market additional capacity or lower its prices. Having a list of all booked orders on a voyage will enable me to generate a manifest of all containers expected or in transit on that voyage. This is required as part of the customs and export clearances and also for review and approval by ship operations to ensure that the cargo loading for this voyage is acceptable/safe. The attributes associated with new order are used to schedule and trigger and monitor: trucking operations, customs and export operations, pickup and delivery confirmations, ship load and unload operation.","title":"Voyages Microservice:  Create new order and Assign to Voyage - user story"},{"location":"design/#voyage-microservice-find-voyages-for-port-pair-and-time-interval-user-story","text":"As the person in Container Shipping company, K.Containers, reponsible for keeping track of shipment orders we have accepted and responding to customer order requests for new shipment orders, I need to be able to query the voyages records to find a list of voyages for a specific port-pair, with source port loading after a specifed start date and destination port unloading before a specified end date. This is the set of voyages I need to check for available capacity (using created new order and assign to voyage) when trying to determine whether a new shipment request from a customer can be satisfied by K.Containers shipping or not.","title":"Voyage Microservice: find voyages for port pair and time interval - user story"},{"location":"design/#fleetsships-microservice-concept","text":"This service keeps track of each of the container ships available for transporting containers. Each ship has a unique shipID. The information about each ship is kept in a keystore keyed by shipID. The ships may be organized into Fleets. A ship record is created when a new ship is commissioned, joins the fleet and becomes available to carry containers as part of the shipping service. We can think to this as being triggered by some \"New ship event\" on the event bus. Each ship record will carry attributes of the ship including its full name and registry. An important attribute from the point of view of processing shipment orders and quote requests is the carrying capacity of the ship. How many containers can it carry on any voyage? We can accept additional shipment bookings only for voyages where there will be space available to carry them on the ship. In addition to its ShipID Key and attributes including capacity (number of containers it is designed to carry). As part of the other important information is the events related to the ship to record things which have happened to that ship. This list will include: GPS lat/log position reports of the position of the ship a different points in time. Events of the ship starting or completing a specific scheduled \"voyage\" - sailing from source port to destination port as scheduled for this ship. Clearances for the ship to enter or leave territorial waters of a nation or port. Arrival at a port dock and start or completion of a ship load / load operation at the dock. Organizing the ship record in this way is an example of event sourcing ; all event relating specifically to a ship are saved. Using queries with time stamp, shipID it is possible to get a complete history of all events relevant to it.","title":"Fleets/Ships Microservice - concept"},{"location":"design/#voyages-microservice-concept","text":"This service keeps track of each scheduled, current or completed voyage of a container ship, being loaded with containers at a source port, sailing to a destination port and having onboard containers unloaded there. The life cycle of a voyage is as follows: Voyages are scheduled some number of months in advance - typically in response to some predictive model for how much demand is expected for shipment taffic in the future for a specific source port destination port pair. * each voyage is assigned a unique voyageID at the time it is created. Each voyage is assigned to be handled by a specific ship, and will have expected dates for: * start and completion loading at the source port. * leaving the source port and travelling to the destination port. * arrival into unloading dock at the destination port and start and completion of unloading at that port. When a voyage is scheduled and before it is actually in progress, bookings (and cancellations) to carry containers can be accepted. * the capacity of the assigned ship determines the maximum number of containers which can be carried on the voyage; available capacity on the voyage must be tracked and booking accepted only until the voyage is fully booked When the expected source port loading date is reached and the voyage actually begins, there may be voyage events recording actual dates for arrival at the destination port etc..., which may be different from the expected dates. * since each ship is expecting to execute a sequence of voyages, delays on one voyage may force rescheduling expected dates or cancellations of follow on voyages. * A voyage is eventually completed. The voyage record, keyed by voyageID, will continue to be important for a while for auditing and billing activities but will eventually be archived. Voyage records play an important role in: * processing shipment quote requests - when could a container be delivered to this destination from this source? * processing a shipment order - when a container is actually booked for a specific voyage * providing a current manifest of which orders/containers are present or expected on the ship for a specific voyage Command Query Responsibility Separation (CQRS) may be important to the design of the voyage microservice to handling the processing above with ideal scalability and responsiveness. It is important that from the perspective of a single voyage, that at all time there is an accurate and reliable list of which orders have been accepted for the voyage and what is the ammount of capacity still available on that voyage for future bookings. Hence there needs to be an atomic method assign_order_to_voyage( ) which adds the order event to the voyage and decrements the free capacity count by one. Since this operation updates the voyage record, it is a command in the CQRS sense. When responding to a request for quote or getting a list of voyages which could be candidate placements for a booking, an important query is: Find_Voyages_With_Capacity() : i.e. find all voyages from source port A to destination port B .. which will leave the source port AFTER goods available date .. AND will arrive at destination port BEFORE goods delivery required date .. AND have bookable freespace Any such voyage can be used to respond to a quote or used as a target to try assigning a booking. If requests for shipment quotes are significantly more frequent than actual bookings, one could provide maximal scalability and rsponsiveness by doing a fully separated CQRS design. The actual table of voyages with accurate and realiable capacity counts for each voyage would be handled in an orders command service with n assign_Order_To_Voyage( ) command api. Requests to check for voyages likely to have availabity for a specific port piar in a specific time window, could be handled by a separate query service with voyage information indexed by port-pair and sorted by departure/arrival date. Whenever the Assign_Order_to_Voyage( ) command succeeds, it generates a new_order_booked event on the event bus. The Find_Voyages_with_Capacity( ) service subscribes to these events and uses them to keep its capacity information on each voyage approximately and eventually correct. This illustrates use of the CQRS pattern to allow the available space query service to be scaled over many processors while ensuring reliable processing of actual booking commands against individual voyages. In addition to capacity, each voyage record will maintin a list of all Orders assigned to to it, allowing generation of a full manifest for expected or actual contents of the ship. In the simplified example we are developing here, we do not worry about order cancellations or modifications; in a pratical production implementation the voyage record would also hold order cancel and order modify event using event sourcing to generate a reliable current manifest from the voyage event history. Read more on EDA design pattern...","title":"Voyages microservice  - concept"},{"location":"introduction/","text":"Introduction As part of producing the IBM event driven point of view and reference architecture, we wanted to bring together a complete scenario which would cover all aspects of developing an event driven solutions including extended connections to devices/IOT and blockchain for trusted business trading networks. We felt that the shipping business could provide a good foundation for this and would enable us to show how to develop event driven solutions following the architecture patterns. The high level process can be represented in the following diagram, and is described in detailed in this section : In developing the scenario, it became apparent that the event driven nature of business, extends across the business network, so we have widened the view in the scenario to consider the chain of parties involved in the shipping process, including importer, exporter, land transport and customs. To keep the scenario easy to understand, we have only considered the following cases: Importer Orders goods from exporter overseas Exporter becomes the customer of the shipping agent and uses 'K.Container' shipping service Shipping agent manages process of land transport loading, unloading and shipping. Through the scenario we can see the impact of \u201cevents\u201d, which may delay or change the shipping process across all three parties. We are using goods to be transported in refrigerator containers or reefer containers to keep the 'cold chain' of transported products.","title":"Introduction"},{"location":"introduction/#introduction","text":"As part of producing the IBM event driven point of view and reference architecture, we wanted to bring together a complete scenario which would cover all aspects of developing an event driven solutions including extended connections to devices/IOT and blockchain for trusted business trading networks. We felt that the shipping business could provide a good foundation for this and would enable us to show how to develop event driven solutions following the architecture patterns. The high level process can be represented in the following diagram, and is described in detailed in this section : In developing the scenario, it became apparent that the event driven nature of business, extends across the business network, so we have widened the view in the scenario to consider the chain of parties involved in the shipping process, including importer, exporter, land transport and customs. To keep the scenario easy to understand, we have only considered the following cases: Importer Orders goods from exporter overseas Exporter becomes the customer of the shipping agent and uses 'K.Container' shipping service Shipping agent manages process of land transport loading, unloading and shipping. Through the scenario we can see the impact of \u201cevents\u201d, which may delay or change the shipping process across all three parties. We are using goods to be transported in refrigerator containers or reefer containers to keep the 'cold chain' of transported products.","title":"Introduction"},{"location":"prepare-ibm-cloud/","text":"Prepare IBM Cloud Services to run the solution IBM Cloud offers a set of services to run part of your event driven architecture. We are using the following services for our reference implementation: Kubernetes Service Streaming Analytics Service * Event Streams At the high level the deployed solution will look like the following: Pre-requisites Create an account on IBM Cloud . Install the following CLIs: Docker CLI IBM Cloud CLI IBM Cloud Kubernetes Service plug-in using the following command: sh $ ibmcloud plugin install container-service -r Bluemix Kubernetes CLI IBM Cloud Container Registry plug-in sh $ ibmcloud plugin install container-registry -r Bluemix The following diagram illustrates the command lines interface and how they interact with IBM Cloud components: All our docker images for this solution are in public docker registry: dockerhub under the ibmcase namespace . This means using our images may work for your deployment if you configure the secrets and other configuration files to point to your services (see detail in this section ) It is recommended that you use your own private image repository, so the following section should be performed. Define an image private repository Use the docker container image private registry to push your images and then deploy them to IBM Kubernetes Service. When deploying enterprise application it is strongly recommended to use private registry to protect your images from being used and changed by unauthorized users. Private registries must be set up by the cluster admin to ensure that the credentials to access the private registry are available to the cluster users. In the Catalog Use the Containers category and Container Registry tile. Create the repository with the create button. You can share a repository for multi IKS clusters. Once you access your registry, create a namespace for your solution. We used ibmcaseeda . We will use this namespace when tagging the docker images for our microservice. But first let add a kubernetes cluster. Kubernetes Cluster Service If you need to know more about kubernetes, read the basic concepts here . To create the cluster follow this tutorial . Here is an image of our cluster, with 3 nodes and the smallest configuration: To access to the cluster use the following command: # login to IBM Cloud. Do not need to be done each time. $ ibmcloud login -a https://api.us-east.bluemix.net # Target the IBM Cloud Container Service region in which you want to work. $ ibmcloud cs region-set us-east # You may need to update the CLI, as it changes quite often $ ibmcloud plugin update container-service # Set the KUBECONFIG environment variable. $ export KUBECONFIG=/Users/$USER/.bluemix/plugins/container-service/clusters/fabio-wdc-07/kube-config-wdc07-fabio-wdc-07.yml # Verify you have access to your cluster by listing the node: $ kubectl get nodes To set the cluster config to your cluster use: ibmcloud ks cluster-config <cluster_name_or_ID> As it is recommended to ilosate your deployment from kubernetes default setting, create a namespace that can be the same as the container registry namespace name or something else. Below we create the browncompute namespace: kubectl create namespace browncompute . Event Streams Service on IBM Cloud To provision your service, go to the IBM Cloud Catalog and search for Event Streams . It is in the Integration category. Create the service and specify a name, a region, and a space. In the service credentials create new credentials to get the Kafka broker list, the admim URL and the api_key needed to authenticate the consumers or producers. We will use a kubernetes secret to define the api key (see detail in this section ) * In the Manage panel add the topics needed for the solution. We need at least the following: Streaming Analytics Service The documentation located here describes how to configure the IBM Cloud based Streaming Analytics Service and how to build/deploy the example application. Using API keys The Event streams broker api key is needed to connect any deployed consumers or producers within kubernetes cluster to access the service in IBM Cloud. To avoid sharing the key with public github we propose to define a kubernetes secret and deploy it to the IKS cluster. The template (file: api-secret-tmpl.yml) for this secret is in the docker folder. Use the following command to deploy the secret into kubernetes cluster under the browncompute namespace: $ kubectl create -f api-secret.yml -n browncompute Verify it is configured: $ kubectl describe secret es-secret -n browncompute Name: es-secret Namespace: browncompute Labels: Annotations: Type: Opaque Data ==== apikey: 36 bytes The secret will be accessed via environment variable so when defining pod we will add reference to this secret. Something like the following definition: env: - name: KAFKA_APIKEY valueFrom: secretKeyRef: name: es-secret key: apikey See an example in the fleet ms deployment.yml","title":"Prepare IBM Cloud Services to run the solution"},{"location":"prepare-ibm-cloud/#prepare-ibm-cloud-services-to-run-the-solution","text":"IBM Cloud offers a set of services to run part of your event driven architecture. We are using the following services for our reference implementation: Kubernetes Service Streaming Analytics Service * Event Streams At the high level the deployed solution will look like the following:","title":"Prepare IBM Cloud Services to run the solution"},{"location":"prepare-ibm-cloud/#pre-requisites","text":"Create an account on IBM Cloud . Install the following CLIs: Docker CLI IBM Cloud CLI IBM Cloud Kubernetes Service plug-in using the following command: sh $ ibmcloud plugin install container-service -r Bluemix Kubernetes CLI IBM Cloud Container Registry plug-in sh $ ibmcloud plugin install container-registry -r Bluemix The following diagram illustrates the command lines interface and how they interact with IBM Cloud components: All our docker images for this solution are in public docker registry: dockerhub under the ibmcase namespace . This means using our images may work for your deployment if you configure the secrets and other configuration files to point to your services (see detail in this section ) It is recommended that you use your own private image repository, so the following section should be performed.","title":"Pre-requisites"},{"location":"prepare-ibm-cloud/#define-an-image-private-repository","text":"Use the docker container image private registry to push your images and then deploy them to IBM Kubernetes Service. When deploying enterprise application it is strongly recommended to use private registry to protect your images from being used and changed by unauthorized users. Private registries must be set up by the cluster admin to ensure that the credentials to access the private registry are available to the cluster users. In the Catalog Use the Containers category and Container Registry tile. Create the repository with the create button. You can share a repository for multi IKS clusters. Once you access your registry, create a namespace for your solution. We used ibmcaseeda . We will use this namespace when tagging the docker images for our microservice. But first let add a kubernetes cluster.","title":"Define an image private repository"},{"location":"prepare-ibm-cloud/#kubernetes-cluster-service","text":"If you need to know more about kubernetes, read the basic concepts here . To create the cluster follow this tutorial . Here is an image of our cluster, with 3 nodes and the smallest configuration: To access to the cluster use the following command: # login to IBM Cloud. Do not need to be done each time. $ ibmcloud login -a https://api.us-east.bluemix.net # Target the IBM Cloud Container Service region in which you want to work. $ ibmcloud cs region-set us-east # You may need to update the CLI, as it changes quite often $ ibmcloud plugin update container-service # Set the KUBECONFIG environment variable. $ export KUBECONFIG=/Users/$USER/.bluemix/plugins/container-service/clusters/fabio-wdc-07/kube-config-wdc07-fabio-wdc-07.yml # Verify you have access to your cluster by listing the node: $ kubectl get nodes To set the cluster config to your cluster use: ibmcloud ks cluster-config <cluster_name_or_ID> As it is recommended to ilosate your deployment from kubernetes default setting, create a namespace that can be the same as the container registry namespace name or something else. Below we create the browncompute namespace: kubectl create namespace browncompute .","title":"Kubernetes Cluster Service"},{"location":"prepare-ibm-cloud/#event-streams-service-on-ibm-cloud","text":"To provision your service, go to the IBM Cloud Catalog and search for Event Streams . It is in the Integration category. Create the service and specify a name, a region, and a space. In the service credentials create new credentials to get the Kafka broker list, the admim URL and the api_key needed to authenticate the consumers or producers. We will use a kubernetes secret to define the api key (see detail in this section ) * In the Manage panel add the topics needed for the solution. We need at least the following:","title":"Event Streams Service on IBM Cloud"},{"location":"prepare-ibm-cloud/#streaming-analytics-service","text":"The documentation located here describes how to configure the IBM Cloud based Streaming Analytics Service and how to build/deploy the example application.","title":"Streaming Analytics Service"},{"location":"prepare-ibm-cloud/#using-api-keys","text":"The Event streams broker api key is needed to connect any deployed consumers or producers within kubernetes cluster to access the service in IBM Cloud. To avoid sharing the key with public github we propose to define a kubernetes secret and deploy it to the IKS cluster. The template (file: api-secret-tmpl.yml) for this secret is in the docker folder. Use the following command to deploy the secret into kubernetes cluster under the browncompute namespace: $ kubectl create -f api-secret.yml -n browncompute Verify it is configured: $ kubectl describe secret es-secret -n browncompute Name: es-secret Namespace: browncompute Labels: Annotations: Type: Opaque Data ==== apikey: 36 bytes The secret will be accessed via environment variable so when defining pod we will add reference to this secret. Something like the following definition: env: - name: KAFKA_APIKEY valueFrom: secretKeyRef: name: es-secret key: apikey See an example in the fleet ms deployment.yml","title":"Using API keys"},{"location":"prepare-icp/","text":"Prepare IBM Cloud Private to run the solution","title":"Prepare IBM Cloud Private to run the solution"},{"location":"prepare-icp/#prepare-ibm-cloud-private-to-run-the-solution","text":"","title":"Prepare IBM Cloud Private to run the solution"},{"location":"analysis/readme/","text":"Container Shipment Analysis This section defines the overall steps in the methodology to analyse a specific global shipping example and derive the event driven solution. We combined some elements of the design thinking methodology with the event storming and domain driven design to extract the following analysis of the business domain. Output from Domain Driven Design workshop From the design thinking workshop we extracted the following artifacts: a persona list the MVP hills Personas for each stakeholder We develop personas for each of the business stakeholders to better understand their work environment, motivations and challenges. Personas helps to capture the decisions and questions that these stakeholders must address with respect to the targeted key business initiative. Persona name Objectives Challenges Retailer Receive shipped goods on time, on date contracted with manufacturer Receive assurance that temperature sensitive goods have remained with bounds Late delivery may miss market opportunity long delivery time makes market opportunitiy prediction more difficult Manufacturer Good enough estimates of shipment times from Shipment Company to close sale and delivery with Retailer Pickup of containers by land transporter Timely delivery of container to Retailer as contracted with Shipment company Able to get information on current location and state of container in transit Contract with Shipment company will include timing estimates and penalty clauses must update Retailer as sonn as schedule changes known Must receive and communicate to retailer assurance on history of temperature sensitive goods Shipping Company Provide good enough estimates of shipment time to close shipment contract with Manufacturer Execute shipment contracts on time profitably ( with minimal cost) Fixed ship and itinerary schedule variability in ship leg travel times and costs variability in port congestion and load / unload times at dock variability in Land transport timings Land Transporter Pick up and drop off containers at times and locations agreed with Shipment company May be short notice requests may actually use bids in a market to resolve at lowest cost best response etc. Port Dock Operator Load and unload containers from docked ship as specified by Shipping Company with minimal time and effort free up dock asset quickly to become available for next ship Highly complex sequence of operation in Dockyard to be coordinated to minimize effort and time Customs Officer Clear containers for export and assess duty on import containers Depends on quality of manifest and certification of origin documentation for each container from Manufacturer MVP hills The challenges listed in the persona table above identify a possible set of MVP hills for this end to end solution. The event storming methodology described below will lead to picking out specific subareas of the solution with most value as initial MVPs. High level view of the shipment process flow At the high level the shipment process flow is suggested and illustrated in the diagram below. For the purposes of showing how to design a reference EDA solution we select on a simple subcase of all actual and possible variations of the global container flow. Very high level steps in this flow are as follows: 1. Retailer and manufacturer interact to create agreement to deliver specific goods in a container from manufacturer's location to retailer's location with an expected arrival date. 1. Manufacturer places shipping order with 'Shipping Company' to pickup container and deliver under the condition expected above. 1. Shipping Company arranges for land transport to pick up loaded container and required documentation from Manufacturer and deliver the container to dockside at source port (adjacent to Maufacturer) for loading onto container carrier. 1. Shipping company works with Customs Officer at source port to clear outbound container for export. 1. When Container Ship is in dock at source port Shipping company arranges with Port Dock Operator to load and unload containers at this port. 1. Loaded container ship leaves dock in source port adjacent to Manufacturer and sails to destination port. 1. Container ship arrives at destination port (adjacent to Retailer) and queues to enter Port Docking area. 1. Shipment company arranges with Port Docking Operator to unload specific containers needed at this port and reload additional ones for next shipping leg. 1. Shipment company works with Import Export office at destination port to clear and collect any import duties. 1. Shipment company works with Land Transporter at destination port to pick up container and deliver to Retailer. 1. Container is delivered by Land Transporter to Retailer's location - transaction is complete. Event storming analysis of the container shipping flow We use the event storming analysis to move from the high level description of a business process flow above to a specific event timeline with identified bounded contexts each of which could be a target MVP component linked through EDA architecture. Event storming is a rapid lightweight design process enabling the team of business owners and stake holders, architects and IT specialists to fomalize a complex solution in a clearly communicable event timeline. This step is effective in developing event-based microservices linked through an EDA architecture in one or more MVP contexts. Steps in an eight hours event storming analysis workshop of the container shipping example are illustrated and described below. Event storming the container shipment example part1: capture the Domain Event Timeline, swim lanes and key phases (This section of the example description covers activities identified as event storming workshop steps 1,2,3 in the generic description of the event storming method ). The initial step in event storming analysis is to capture all events, things which have happened at a point in time, and organize them into a timeline. each event goes on an orange \"sticky note\" parallel or independent processes may be separated with blue horizontal swim lanes * critical event indicate a new stage, or pivot, in the flow shown with vertical blue bars. For the global shipment example described at a very high level above we came up with an event timeline shown in the set of diagrams below. (The event storming process captures these event timeline sections in charts on walls around the meeting room). Container shipping event timeline section 1 This section of the event time line deals with initial contracts to ship container and startup actions - specifically: Retailer and Manufacturer settling on an initial order for delivery of goods in a container. Manufacturer placing order for shipment with Shipping Company. Land transport arranged to pick up container and deliver to source port. Container ship approach source port adjacent to Manufacturer's location. The events are organized into separate swim lanes for Manufacturer, Retailer and Ship perspectives operating in parallel. Swim lanes help to clearly separate ship events as it approaches the source port from container specific events with agreements to ship etc. There is no time coupling or precise causality between events in these two swim lanes. The red note is a comment. * In this case we make the particular simplification to limit the scenario to shipping complete containers only. This avoids having to deal with additional warehousing, container load aggregation and packing events - together with correspondng unpacking and disaggregation. Container shipping event timeline section 2 This section continues event time line development with a swim lane now focussing on loading and pickup of a specific container at the Manufacturer's location and its delivery to the source port dockside. There is a critical event (indicated by vertical blue bar) separating the \"source dockside\" phase of the solution. Before this critical event we are dealing with container specific activities in collecting and transporting the container from Manufacturer's location to dockside. In the following dockside phase there are interactions with Customs Officer to get the container cleared for export. The Manufacturer will need an empty container (refrigerated if necessary for the shipment of interest) to load the goods into. We show an event for empty container being delivered. The solution is simplified if we assume that the Manufacture has a pool of empty containers always available. Alternatively this can be analyzed fully in some more complete generalized version of the solution. When the container arrives at source port dockside it may or may not be intime for the cutoff time required by the Customs Officer to get containers cleared for export before the scheduled departure of a particular container ship. If the cutoff deadline is missed the shipment will need to be rebooked on a later container ship and the client Manufacturer notified of expected delay in delivery. Container shipping event timeline section 3 This section continues the event timelines with swim lanes relating to a specific container shipment and also to the movement of a ship potentially carrying hundreds of containers. It introduces two new critical events: The Customs decision phase of event ends with a specific decision to clear a container for export or not, or possibly a request for additional inspecions or documents requiring more decision time * If the container is approved for export it can proceed to loading. * If additional time is required for the clearance process, the original booking and expected delivery date may need to be modified. * If export clearance is denied, then shipmen is cancelled and requesting parties notified. Ship enters dock ready to start unloading and loading is a new critical event. * Previous ship events in Event Timeline section 1 dealt with ship \"booking\" a load/unload timeslot at a dock in the source port * Also getting national authority or Customs clearance to enter that jurisdiction * Now on arrival at the source port anchorage area, the ship requests permission to moor at an available dock facility * The critical event when a ship is cleared and moored at a dock hence ready to start unloading and loading containers is the start of the next event phase - container loading (and unloading) Container shipping event timeline section 4 This segment of the event timeline deals with a single swim lane for the ship while it is moored in a dock facility at the source port, is having arriving containers destined for this port unloaded and new containers being loaded at his port. The port dock facility operator is coordinating many events in the yard to perform load unload operations. These steps - as noted in a red discussion \"sticky\" in the event storming timeline are repeated for many containers. The time line presented here captures representative high level events. It is straightforward to extend the analysis to open up additional layers of detail touching on operational optimizations and coordination at the cost of addiional complexity not essential to our reference example here. Some of the events in this phase are now specialized to address needs of particular type of container - refrigerated containers - able to maintain specific temperature bounds and to report on their global location and temperature status on a continuous basis. This is a natural outcome of the event storming analysis involving free parallel capture of event types by a team of individuals with different points of view and interests. Working forward towards one or more MVP implementations of key components of this solution linked through EDA architecture we will need to characterize event types more uniformly end to end but imposing that level of consistency checking on the initial event storming process will slow down progess without providing significant benefit. Container shipping event timeline section 5 This segment of the event timeline captures events which occure in the blue water phase of the shipping, after the container ship has left the source port and is travelling owards but has not yet reached the destination port. It is divided into two swim lanes the ship perspective and individual container perspectives. The ship perspective includes events relating to the entire ship: leaving port. reporting its current position. * deciding to alter planned course to avoid a weather event. The upper swim lane capture events which are specific to a particular container. container sensors reporting on geolocation. refrigerated container sensors reporting on humidity, carbon dioxide, temperature in the container and power consumption of the refrigeration unit. Container shipping event timeline sections 6 and 7 The remining event time line segments 6 and 7 deal with arrival at the destination port unload of the container and delivery to the Retailer's location. At the level of simplification in the reference architecture example, the steps for unloading a container at the destination port, clearing Customs and delivering it to are Retailer location are the symmetric image of the steps to pick up the container from the Manufacture location, clear it through export permissions and load onto the ship. For these reason we just provide event timeline digrams for these steps withou going into further explanatory detail. Event storming the container shipment example part 2: identify commands and event linkages (This section of the example description covers activities identified as event storming workshop steps 4,5) in the generic description of the event storming method . ) After capturing all events for the scenario and organizing them in a time line, the next step in event storming analysis is to identify the triggers for events and causal linkages between events. For each identified event in the timeline we ask \"What triggered this event to occur?\". Expected event trigger types are: A human operator makes a decision and issues a command. Some external system or sensor provides a stimulus. An event results from some policy - typically automated processing of a precursor event. Completion of some determined period of elapsed time. For each event trigerred by a command the triggering command is identified in a blue (sticky) note * this may become a microservice api in a later implementation the human persona issuing the command is identified and shown in a yellow note above this. For events trigerred by processing of some precursor events the trigerring policy explaining when and why this event occurs is summarized in a lilac colored note. Specific causal event linkages are added to the event storming diagram as blue directed (arrow) linkages. In the following subsections we show the results of command and event linkage analysis for some selected areas of the container shipping example. Container shipping Commands for order placement and land transport setup This diagram shows the command, agent issuing events and policies triggering events for the order placement and land transport set up (at manufacturer location) sections of the event timeline generated in step 1 Container shipping event linkages for order placement setup The above diagram adds event linkages showing the causality chaining of events. Container shipping commands for pickup at Manufacturer's location The above diagram is generated for the command and policies associated with pick up of a loaded container from the Manufacturer's location and delivery to the source port dockside. Container shipping commands in port to port (Blue water) section of the event time line The diagram is self explanatory. Event storming the container shipment example part 3: Decision data, predictive insights and insight storming: (This section of the example description covers activities identified as event storming workshop step 8) in the generic description of the event storming method . Insight storming is extending the event storming workshop to identify and capture insightful predictive analytics, and it is introduced and described in workshop execution Step 8 - Insight . Predictive analytic insights are effectively probabilistic statements about which future events are likely to occur and what are the like properties of those events. They are typicaly generated using models created by data scientists or using artificial intelligence (AI) or machine learning (ML). Business owners and stakeholders in the event driven solution have good intuitions on: Which probabilistic insights are likely to lead to better decision making and action when a particular event occurs. What sources of information are likely to help create a model to predict this insight. So in event storming for an EDA system, we recommend generalizing the step of identifying data (properties of past definite events) to help make good decision and replacing this with an insight storming step which will look for: data which will help make good decisions about how to act when an event occurs predictive insights which could help guide our actions in response to proactively before some future event. * sources of data which are likely to enable the building of reliable predictive insight models. This additional step of insight storming takes advantage of the fact that we already have a time line for the problem being analysed with all events designed, commands, policies and event linkages already identified, and the business owners and stakeholders in the room whose insights for the business problem enable them to identify potentially valuable predictive insights. Working through insight storming in this way leads to a business value driven specification of possible predictive analytics opportunities in the solution. Event driven architecture provides a mature pattern to models addressing the identified needs. Event Stream Processing analytics infrastructure is then availalable to support scoring of these models and uses of the resulting insights in decision making and action in real time. Container shipping event stream processing diagram - including event stream processing flows The shipping example includes the case where continuous sensor measurement data is available from each refrigerated container while it is stacked on board the container ship and is in between ports on a blue water phase of the scenario. We show how streaming analytics can process the arriving continuous sensor measures in real-time and to deliver additional capabilites in the EDA solution. A diagram for this flow generated from Insight storming is shown below. In this diagram it is made clear the delivery of measured temperature, probably GPS position, and power consumption of the refrigeration unit for that container is a recurring \"continuous\" event stream. Each container might report once a minute; this ensures that an auditable record of container temperature is available from the event backbone or event sourcing. We show a policy test to decide whether the temperature has gone outside the specified range committed to in that shipment contract for the goods in that container. If this violation has occured, this is an (unusual) alert event reporting that temperature has gone out of range. This information is available as data to subject matter expert's dashboard seen by the shipping company operator who must make the business decision whether the contents of the container are spoiled. It is likely that involvement of human operator is necessary since this is a business decision with possibly significant $ consequences. It is possible that a bad sensor reading could have been received or that in this contract violation of the temperature range for a very short interval of time is permissable. Some stateful analysis of the container temperature reports would make the readings more reliable; perhaps there need to be more than one out of range reading to issue the alert to avoid corrupted data false positives. If the business decision is made that the container's contents are spoiled: A command is invoked to act on this decision. The container refrigeration may be powered down (possible other sensing left active) * A policy based on terms and class of service of this particular shipment will determine: * Whether a replacement shipment will be initiated and booked * Usually shipping and receiving parties need to be notified * The shipping company will schedule some salvage or disposal action for the content of the container at next port Each of the actions above will be an event captured in the event backbone - trigerring further loosely coupled commands and policies to take defined actions. Container shipping event stream processing with predictive Insight flows included The previous section defines how event stream processing could detect when a shipment was spoiled and trigger recovery actions. But shipping experts in an insight storming session will note that it is much better to predict when a spoilage temperature event is likely to occur and to take automated immediate (real-time) action to avert the spoilage. The simplest form of prediction of a temperature likely to go outside of its permissible range is to have checks on whether the temperature is approaching these bounds. If the temperature must stay below T degrees, take corrective action if it reaches T - delta degrees. More complex models for predicting temperature, could take into account diurnal variation due to external temperatures, possible predicted external temperatures forecast for the current course of the ship, and whether ther container is stacked above deck and hence particularly exposed to external temperatures. We assume that possible corrective action includes resetting the thermostatic controls on the refrigeration unit for the cotainer, possibly resetting the controls which may have drifted from their calibrated settings... An insight storming diagram which could be generated from discussion of these potentially useful insights and predictions is shown in the diagram below. We have added an additional insight - namely that it may be possible to predict from the temperature observed in a container and the trend of power consumption of that refrigeration unit, that the unit is in danger of failing and should be inspected and possibly services as soon as possible. Insights about predicted risk of temperature based spoilage, and prediction of refrigeration unit probable need for maintenance are presented in light blue. These are probabilistic prediction for properties and likely occurence of future events. Loose coupling and reuse of these insights by allowing publish subscribe to insight topics is helpful. Insights are conceptually different from events since they are probabilistic predictions for the future rather than events which by definition have already happened at some specific point in time. Event stream processing for insights relating to the ship Event storming the container shipment example part 4: Commands, linkages, data and context for order placement (This section of the example description covers activities identified as EventStorming Workshop steps 6,7) in the generic description of the event storming method . ) In particular, we look at identifying bounded contexts and identifying aggregates which will lead to a loosely coupled collection of microservices providing an agile EDA design for the example. We drill down on understanding the order placement process when a container shipment is booked as the MVP context focus in which to explore our design at the next level of detail.","title":"Analysis"},{"location":"analysis/readme/#container-shipment-analysis","text":"This section defines the overall steps in the methodology to analyse a specific global shipping example and derive the event driven solution. We combined some elements of the design thinking methodology with the event storming and domain driven design to extract the following analysis of the business domain.","title":"Container Shipment Analysis"},{"location":"analysis/readme/#output-from-domain-driven-design-workshop","text":"From the design thinking workshop we extracted the following artifacts: a persona list the MVP hills","title":"Output from Domain Driven Design workshop"},{"location":"analysis/readme/#personas-for-each-stakeholder","text":"We develop personas for each of the business stakeholders to better understand their work environment, motivations and challenges. Personas helps to capture the decisions and questions that these stakeholders must address with respect to the targeted key business initiative. Persona name Objectives Challenges Retailer Receive shipped goods on time, on date contracted with manufacturer Receive assurance that temperature sensitive goods have remained with bounds Late delivery may miss market opportunity long delivery time makes market opportunitiy prediction more difficult Manufacturer Good enough estimates of shipment times from Shipment Company to close sale and delivery with Retailer Pickup of containers by land transporter Timely delivery of container to Retailer as contracted with Shipment company Able to get information on current location and state of container in transit Contract with Shipment company will include timing estimates and penalty clauses must update Retailer as sonn as schedule changes known Must receive and communicate to retailer assurance on history of temperature sensitive goods Shipping Company Provide good enough estimates of shipment time to close shipment contract with Manufacturer Execute shipment contracts on time profitably ( with minimal cost) Fixed ship and itinerary schedule variability in ship leg travel times and costs variability in port congestion and load / unload times at dock variability in Land transport timings Land Transporter Pick up and drop off containers at times and locations agreed with Shipment company May be short notice requests may actually use bids in a market to resolve at lowest cost best response etc. Port Dock Operator Load and unload containers from docked ship as specified by Shipping Company with minimal time and effort free up dock asset quickly to become available for next ship Highly complex sequence of operation in Dockyard to be coordinated to minimize effort and time Customs Officer Clear containers for export and assess duty on import containers Depends on quality of manifest and certification of origin documentation for each container from Manufacturer","title":"Personas for each stakeholder"},{"location":"analysis/readme/#mvp-hills","text":"The challenges listed in the persona table above identify a possible set of MVP hills for this end to end solution. The event storming methodology described below will lead to picking out specific subareas of the solution with most value as initial MVPs.","title":"MVP hills"},{"location":"analysis/readme/#high-level-view-of-the-shipment-process-flow","text":"At the high level the shipment process flow is suggested and illustrated in the diagram below. For the purposes of showing how to design a reference EDA solution we select on a simple subcase of all actual and possible variations of the global container flow. Very high level steps in this flow are as follows: 1. Retailer and manufacturer interact to create agreement to deliver specific goods in a container from manufacturer's location to retailer's location with an expected arrival date. 1. Manufacturer places shipping order with 'Shipping Company' to pickup container and deliver under the condition expected above. 1. Shipping Company arranges for land transport to pick up loaded container and required documentation from Manufacturer and deliver the container to dockside at source port (adjacent to Maufacturer) for loading onto container carrier. 1. Shipping company works with Customs Officer at source port to clear outbound container for export. 1. When Container Ship is in dock at source port Shipping company arranges with Port Dock Operator to load and unload containers at this port. 1. Loaded container ship leaves dock in source port adjacent to Manufacturer and sails to destination port. 1. Container ship arrives at destination port (adjacent to Retailer) and queues to enter Port Docking area. 1. Shipment company arranges with Port Docking Operator to unload specific containers needed at this port and reload additional ones for next shipping leg. 1. Shipment company works with Import Export office at destination port to clear and collect any import duties. 1. Shipment company works with Land Transporter at destination port to pick up container and deliver to Retailer. 1. Container is delivered by Land Transporter to Retailer's location - transaction is complete.","title":"High level view of the shipment process flow"},{"location":"analysis/readme/#event-storming-analysis-of-the-container-shipping-flow","text":"We use the event storming analysis to move from the high level description of a business process flow above to a specific event timeline with identified bounded contexts each of which could be a target MVP component linked through EDA architecture. Event storming is a rapid lightweight design process enabling the team of business owners and stake holders, architects and IT specialists to fomalize a complex solution in a clearly communicable event timeline. This step is effective in developing event-based microservices linked through an EDA architecture in one or more MVP contexts. Steps in an eight hours event storming analysis workshop of the container shipping example are illustrated and described below.","title":"Event storming analysis of the container shipping flow"},{"location":"analysis/readme/#event-storming-the-container-shipment-example-part1-capture-the-domain-event-timeline-swim-lanes-and-key-phases","text":"(This section of the example description covers activities identified as event storming workshop steps 1,2,3 in the generic description of the event storming method ). The initial step in event storming analysis is to capture all events, things which have happened at a point in time, and organize them into a timeline. each event goes on an orange \"sticky note\" parallel or independent processes may be separated with blue horizontal swim lanes * critical event indicate a new stage, or pivot, in the flow shown with vertical blue bars. For the global shipment example described at a very high level above we came up with an event timeline shown in the set of diagrams below. (The event storming process captures these event timeline sections in charts on walls around the meeting room).","title":"Event storming the container shipment example part1: capture the Domain Event Timeline, swim lanes and key phases"},{"location":"analysis/readme/#container-shipping-event-timeline-section-1","text":"This section of the event time line deals with initial contracts to ship container and startup actions - specifically: Retailer and Manufacturer settling on an initial order for delivery of goods in a container. Manufacturer placing order for shipment with Shipping Company. Land transport arranged to pick up container and deliver to source port. Container ship approach source port adjacent to Manufacturer's location. The events are organized into separate swim lanes for Manufacturer, Retailer and Ship perspectives operating in parallel. Swim lanes help to clearly separate ship events as it approaches the source port from container specific events with agreements to ship etc. There is no time coupling or precise causality between events in these two swim lanes. The red note is a comment. * In this case we make the particular simplification to limit the scenario to shipping complete containers only. This avoids having to deal with additional warehousing, container load aggregation and packing events - together with correspondng unpacking and disaggregation.","title":"Container shipping event timeline section 1"},{"location":"analysis/readme/#container-shipping-event-timeline-section-2","text":"This section continues event time line development with a swim lane now focussing on loading and pickup of a specific container at the Manufacturer's location and its delivery to the source port dockside. There is a critical event (indicated by vertical blue bar) separating the \"source dockside\" phase of the solution. Before this critical event we are dealing with container specific activities in collecting and transporting the container from Manufacturer's location to dockside. In the following dockside phase there are interactions with Customs Officer to get the container cleared for export. The Manufacturer will need an empty container (refrigerated if necessary for the shipment of interest) to load the goods into. We show an event for empty container being delivered. The solution is simplified if we assume that the Manufacture has a pool of empty containers always available. Alternatively this can be analyzed fully in some more complete generalized version of the solution. When the container arrives at source port dockside it may or may not be intime for the cutoff time required by the Customs Officer to get containers cleared for export before the scheduled departure of a particular container ship. If the cutoff deadline is missed the shipment will need to be rebooked on a later container ship and the client Manufacturer notified of expected delay in delivery.","title":"Container shipping event timeline section 2"},{"location":"analysis/readme/#container-shipping-event-timeline-section-3","text":"This section continues the event timelines with swim lanes relating to a specific container shipment and also to the movement of a ship potentially carrying hundreds of containers. It introduces two new critical events: The Customs decision phase of event ends with a specific decision to clear a container for export or not, or possibly a request for additional inspecions or documents requiring more decision time * If the container is approved for export it can proceed to loading. * If additional time is required for the clearance process, the original booking and expected delivery date may need to be modified. * If export clearance is denied, then shipmen is cancelled and requesting parties notified. Ship enters dock ready to start unloading and loading is a new critical event. * Previous ship events in Event Timeline section 1 dealt with ship \"booking\" a load/unload timeslot at a dock in the source port * Also getting national authority or Customs clearance to enter that jurisdiction * Now on arrival at the source port anchorage area, the ship requests permission to moor at an available dock facility * The critical event when a ship is cleared and moored at a dock hence ready to start unloading and loading containers is the start of the next event phase - container loading (and unloading)","title":"Container shipping event timeline section 3"},{"location":"analysis/readme/#container-shipping-event-timeline-section-4","text":"This segment of the event timeline deals with a single swim lane for the ship while it is moored in a dock facility at the source port, is having arriving containers destined for this port unloaded and new containers being loaded at his port. The port dock facility operator is coordinating many events in the yard to perform load unload operations. These steps - as noted in a red discussion \"sticky\" in the event storming timeline are repeated for many containers. The time line presented here captures representative high level events. It is straightforward to extend the analysis to open up additional layers of detail touching on operational optimizations and coordination at the cost of addiional complexity not essential to our reference example here. Some of the events in this phase are now specialized to address needs of particular type of container - refrigerated containers - able to maintain specific temperature bounds and to report on their global location and temperature status on a continuous basis. This is a natural outcome of the event storming analysis involving free parallel capture of event types by a team of individuals with different points of view and interests. Working forward towards one or more MVP implementations of key components of this solution linked through EDA architecture we will need to characterize event types more uniformly end to end but imposing that level of consistency checking on the initial event storming process will slow down progess without providing significant benefit.","title":"Container shipping event timeline section 4"},{"location":"analysis/readme/#container-shipping-event-timeline-section-5","text":"This segment of the event timeline captures events which occure in the blue water phase of the shipping, after the container ship has left the source port and is travelling owards but has not yet reached the destination port. It is divided into two swim lanes the ship perspective and individual container perspectives. The ship perspective includes events relating to the entire ship: leaving port. reporting its current position. * deciding to alter planned course to avoid a weather event. The upper swim lane capture events which are specific to a particular container. container sensors reporting on geolocation. refrigerated container sensors reporting on humidity, carbon dioxide, temperature in the container and power consumption of the refrigeration unit.","title":"Container shipping event timeline section 5"},{"location":"analysis/readme/#container-shipping-event-timeline-sections-6-and-7","text":"The remining event time line segments 6 and 7 deal with arrival at the destination port unload of the container and delivery to the Retailer's location. At the level of simplification in the reference architecture example, the steps for unloading a container at the destination port, clearing Customs and delivering it to are Retailer location are the symmetric image of the steps to pick up the container from the Manufacture location, clear it through export permissions and load onto the ship. For these reason we just provide event timeline digrams for these steps withou going into further explanatory detail.","title":"Container shipping event timeline sections 6 and 7"},{"location":"analysis/readme/#event-storming-the-container-shipment-example-part-2-identify-commands-and-event-linkages","text":"(This section of the example description covers activities identified as event storming workshop steps 4,5) in the generic description of the event storming method . ) After capturing all events for the scenario and organizing them in a time line, the next step in event storming analysis is to identify the triggers for events and causal linkages between events. For each identified event in the timeline we ask \"What triggered this event to occur?\". Expected event trigger types are: A human operator makes a decision and issues a command. Some external system or sensor provides a stimulus. An event results from some policy - typically automated processing of a precursor event. Completion of some determined period of elapsed time. For each event trigerred by a command the triggering command is identified in a blue (sticky) note * this may become a microservice api in a later implementation the human persona issuing the command is identified and shown in a yellow note above this. For events trigerred by processing of some precursor events the trigerring policy explaining when and why this event occurs is summarized in a lilac colored note. Specific causal event linkages are added to the event storming diagram as blue directed (arrow) linkages. In the following subsections we show the results of command and event linkage analysis for some selected areas of the container shipping example.","title":"Event storming the container shipment example part 2:  identify commands and event linkages"},{"location":"analysis/readme/#container-shipping-commands-for-order-placement-and-land-transport-setup","text":"This diagram shows the command, agent issuing events and policies triggering events for the order placement and land transport set up (at manufacturer location) sections of the event timeline generated in step 1","title":"Container shipping Commands for order placement and land transport setup"},{"location":"analysis/readme/#container-shipping-event-linkages-for-order-placement-setup","text":"The above diagram adds event linkages showing the causality chaining of events.","title":"Container shipping  event linkages for order placement setup"},{"location":"analysis/readme/#container-shipping-commands-for-pickup-at-manufacturers-location","text":"The above diagram is generated for the command and policies associated with pick up of a loaded container from the Manufacturer's location and delivery to the source port dockside.","title":"Container shipping commands for pickup at Manufacturer's location"},{"location":"analysis/readme/#container-shipping-commands-in-port-to-port-blue-water-section-of-the-event-time-line","text":"The diagram is self explanatory.","title":"Container shipping commands in port to port (Blue water) section of the event time line"},{"location":"analysis/readme/#event-storming-the-container-shipment-example-part-3-decision-data-predictive-insights-and-insight-storming","text":"(This section of the example description covers activities identified as event storming workshop step 8) in the generic description of the event storming method . Insight storming is extending the event storming workshop to identify and capture insightful predictive analytics, and it is introduced and described in workshop execution Step 8 - Insight . Predictive analytic insights are effectively probabilistic statements about which future events are likely to occur and what are the like properties of those events. They are typicaly generated using models created by data scientists or using artificial intelligence (AI) or machine learning (ML). Business owners and stakeholders in the event driven solution have good intuitions on: Which probabilistic insights are likely to lead to better decision making and action when a particular event occurs. What sources of information are likely to help create a model to predict this insight. So in event storming for an EDA system, we recommend generalizing the step of identifying data (properties of past definite events) to help make good decision and replacing this with an insight storming step which will look for: data which will help make good decisions about how to act when an event occurs predictive insights which could help guide our actions in response to proactively before some future event. * sources of data which are likely to enable the building of reliable predictive insight models. This additional step of insight storming takes advantage of the fact that we already have a time line for the problem being analysed with all events designed, commands, policies and event linkages already identified, and the business owners and stakeholders in the room whose insights for the business problem enable them to identify potentially valuable predictive insights. Working through insight storming in this way leads to a business value driven specification of possible predictive analytics opportunities in the solution. Event driven architecture provides a mature pattern to models addressing the identified needs. Event Stream Processing analytics infrastructure is then availalable to support scoring of these models and uses of the resulting insights in decision making and action in real time.","title":"Event storming the container shipment example part 3: Decision data, predictive insights and insight storming:"},{"location":"analysis/readme/#container-shipping-event-stream-processing-diagram-including-event-stream-processing-flows","text":"The shipping example includes the case where continuous sensor measurement data is available from each refrigerated container while it is stacked on board the container ship and is in between ports on a blue water phase of the scenario. We show how streaming analytics can process the arriving continuous sensor measures in real-time and to deliver additional capabilites in the EDA solution. A diagram for this flow generated from Insight storming is shown below. In this diagram it is made clear the delivery of measured temperature, probably GPS position, and power consumption of the refrigeration unit for that container is a recurring \"continuous\" event stream. Each container might report once a minute; this ensures that an auditable record of container temperature is available from the event backbone or event sourcing. We show a policy test to decide whether the temperature has gone outside the specified range committed to in that shipment contract for the goods in that container. If this violation has occured, this is an (unusual) alert event reporting that temperature has gone out of range. This information is available as data to subject matter expert's dashboard seen by the shipping company operator who must make the business decision whether the contents of the container are spoiled. It is likely that involvement of human operator is necessary since this is a business decision with possibly significant $ consequences. It is possible that a bad sensor reading could have been received or that in this contract violation of the temperature range for a very short interval of time is permissable. Some stateful analysis of the container temperature reports would make the readings more reliable; perhaps there need to be more than one out of range reading to issue the alert to avoid corrupted data false positives. If the business decision is made that the container's contents are spoiled: A command is invoked to act on this decision. The container refrigeration may be powered down (possible other sensing left active) * A policy based on terms and class of service of this particular shipment will determine: * Whether a replacement shipment will be initiated and booked * Usually shipping and receiving parties need to be notified * The shipping company will schedule some salvage or disposal action for the content of the container at next port Each of the actions above will be an event captured in the event backbone - trigerring further loosely coupled commands and policies to take defined actions.","title":"Container shipping event stream processing diagram - including event stream processing flows"},{"location":"analysis/readme/#container-shipping-event-stream-processing-with-predictive-insight-flows-included","text":"The previous section defines how event stream processing could detect when a shipment was spoiled and trigger recovery actions. But shipping experts in an insight storming session will note that it is much better to predict when a spoilage temperature event is likely to occur and to take automated immediate (real-time) action to avert the spoilage. The simplest form of prediction of a temperature likely to go outside of its permissible range is to have checks on whether the temperature is approaching these bounds. If the temperature must stay below T degrees, take corrective action if it reaches T - delta degrees. More complex models for predicting temperature, could take into account diurnal variation due to external temperatures, possible predicted external temperatures forecast for the current course of the ship, and whether ther container is stacked above deck and hence particularly exposed to external temperatures. We assume that possible corrective action includes resetting the thermostatic controls on the refrigeration unit for the cotainer, possibly resetting the controls which may have drifted from their calibrated settings... An insight storming diagram which could be generated from discussion of these potentially useful insights and predictions is shown in the diagram below. We have added an additional insight - namely that it may be possible to predict from the temperature observed in a container and the trend of power consumption of that refrigeration unit, that the unit is in danger of failing and should be inspected and possibly services as soon as possible. Insights about predicted risk of temperature based spoilage, and prediction of refrigeration unit probable need for maintenance are presented in light blue. These are probabilistic prediction for properties and likely occurence of future events. Loose coupling and reuse of these insights by allowing publish subscribe to insight topics is helpful. Insights are conceptually different from events since they are probabilistic predictions for the future rather than events which by definition have already happened at some specific point in time.","title":"Container shipping event stream processing with predictive Insight flows included"},{"location":"analysis/readme/#event-stream-processing-for-insights-relating-to-the-ship","text":"","title":"Event stream processing for insights relating to the ship"},{"location":"analysis/readme/#event-storming-the-container-shipment-example-part-4-commands-linkages-data-and-context-for-order-placement","text":"(This section of the example description covers activities identified as EventStorming Workshop steps 6,7) in the generic description of the event storming method . ) In particular, we look at identifying bounded contexts and identifying aggregates which will lead to a loosely coupled collection of microservices providing an agile EDA design for the example. We drill down on understanding the order placement process when a container shipment is booked as the MVP context focus in which to explore our design at the next level of detail.","title":"Event storming the container shipment example part 4:  Commands, linkages, data and context for order placement"}]}